{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations, product"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input and output directories\n",
    "Where the sql database is and which folder the results are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.path.expanduser(\"~\")\n",
    "\n",
    "# SQL database path and name\n",
    "input_dir = os.path.join(home, 'video_resources', 'sql_database')\n",
    "\n",
    "# path to images\n",
    "image_dir = os.path.join(home, 'video_resources','image_datasets')\n",
    "\n",
    "# Where results are saved\n",
    "output_dir = os.path.join(home, 'video_resources', 'experiment')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images to show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif1 ='xqlfw/Donatella_Versace/Donatella_Versace_0003.jpg'\n",
    "dif2 = 'xqlfw/Mona_Ayoub/Mona_Ayoub_0001.jpg'\n",
    "\n",
    "same1='xqlfw/George_W_Bush/George_W_Bush_0223.jpg'\n",
    "same2='xqlfw/George_W_Bush/George_W_Bush_0183.jpg'\n",
    "\t\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get images and datafram with same identity pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenes = pd.read_pickle(os.path.join(output_dir,'imagenes.pkl'))\n",
    "pd_misma = pd.read_pickle(os.path.join(output_dir,'misma_identidad.pkl'))\n",
    "misma_aleatorio = pd_misma.sample(frac=1).reset_index(drop=True)\n",
    "pd_dif = pd.DataFrame(columns = pd_misma.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(imagenes)\n",
    "m = len(pd_misma)\n",
    "ntotal = int(n*(n-1)/2)\n",
    "\n",
    "aleatoria = random.sample(range(ntotal),2*m)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generador de diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diferentes = ((a[1],b[1]) for a,b in combinations(imagenes.iterrows(), 2) if a[1].identity != b[1].identity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defino la funcion de distancia o similitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hago la funcion coseno por hacer una\n",
    "def similitud(a,b):\n",
    "    a1 = np.array(a)\n",
    "    b1 = np.array(b)\n",
    "\n",
    "    return( np.dot(a1,b1)/(np.linalg.norm(a1)*np.linalg.norm(b1)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obtener diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/240295 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'Dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/jmacarulla/lr-video-face/experiment_B.ipynb Cell 15\u001b[0m in \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jmacarulla/lr-video-face/experiment_B.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m dif \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(diferentes)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jmacarulla/lr-video-face/experiment_B.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m nuevo \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mpath1\u001b[39m\u001b[39m'\u001b[39m: dif[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mpath,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jmacarulla/lr-video-face/experiment_B.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mpath2\u001b[39m\u001b[39m'\u001b[39m: dif[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpath,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jmacarulla/lr-video-face/experiment_B.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mresultado\u001b[39m\u001b[39m'\u001b[39m: similitud(dif[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39membeddings,dif[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39membeddings)}            \n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jmacarulla/lr-video-face/experiment_B.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m pd_dif \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([pd_dif,pd\u001b[39m.\u001b[39;49mDataframe(nuevo)], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/lr-video/lib/python3.8/site-packages/pandas/__init__.py:264\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseArray \u001b[39mas\u001b[39;00m _SparseArray\n\u001b[1;32m    262\u001b[0m     \u001b[39mreturn\u001b[39;00m _SparseArray\n\u001b[0;32m--> 264\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpandas\u001b[39m\u001b[39m'\u001b[39m\u001b[39m has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'Dataframe'"
     ]
    }
   ],
   "source": [
    "#n = len(aleatoria)\n",
    "for indice in tqdm(range (m)):\n",
    "    dif = next(diferentes)\n",
    "    nuevo = {'path1': dif[0].path,\n",
    "            'path2': dif[1].path,\n",
    "            'resultado': similitud(dif[0].embeddings,dif[1].embeddings)}            \n",
    "    \n",
    "    pd_dif = pd.concat([pd_dif,pd.DataFrame(nuevo)], ignore_index=True)\n",
    "             \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_dif.to_pickle(os.path.join(output_dir,'diferentes.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same = [(a[1],b[1]) for a,b in combinaciones if a[1].identity == b[1].identity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same = []\n",
    "different = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in tqdm(combinaciones):\n",
    "    if a[1].identity == b[1].identity:\n",
    "        same.append([a[1].image_id,b[1].image_id])\n",
    "    else:\n",
    "        different.append([a[1].image_id,b[1].image_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado = pd.DataFrame(columns=['path1', 'path2', 'resultado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identities = set(df1.identity)\n",
    "identities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for identity in tqdm(identities) :\n",
    "    dfx = df1.loc[(df1.identity == identity)]\n",
    "    if len(dfx) > 1:\n",
    "        combinaciones = list(combinations(dfx.iterrows(), 2))\n",
    "\n",
    "        # Iterar sobre las combinaciones\n",
    "        for comb in tqdm(combinaciones):\n",
    "            index1, row1 = comb[0]\n",
    "            index2, row2 = comb[1]\n",
    "    \n",
    "            path1 = row1['path']\n",
    "            path2 = row2['path']\n",
    "    \n",
    "            # Realizar la operaci√≥n deseada (ejemplo: suma de los embeddings)\n",
    "            resultado = similitud(row1['embeddings'] , row2['embeddings'])\n",
    "    \n",
    "            # Agregar los resultados al DataFrame de resultado\n",
    "            df_resultado = df_resultado.append({\n",
    "            'path1': path1,\n",
    "            'path2': path2,\n",
    "            'resultado': resultado\n",
    "            }, ignore_index=True)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_resultado):\n",
    "    df_resultado.to_pickle(os.path.join(output_dir,'misma_identidad.pkl'))\n",
    "    df_resultado.to_excel(os.path.join(output_dir,'misma_identidad.xlsx'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscar en diferentes identidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identities = list(set(df1.identity))\n",
    "#identities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado = pd.DataFrame(columns=['path1', 'path2', 'resultado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,identity in enumerate(identities):\n",
    "    print(i)\n",
    "    dfx = df1.loc[(df1.identity == identity)]\n",
    "    dfy = df1.loc[(df1.identity > identity)]\n",
    "    \n",
    "    combinaciones = list(product(dfx.iterrows(), dfy.iterrows()))\n",
    "\n",
    "        # Iterar sobre las combinaciones\n",
    "    df_parcial = pd.DataFrame(columns=['path1', 'path2', 'resultado'])\n",
    "    for comb in tqdm(combinaciones):\n",
    "        \n",
    "        index1, row1 = comb[0]\n",
    "        index2, row2 = comb[1]\n",
    "    \n",
    "        path1 = row1['path']\n",
    "        path2 = row2['path']\n",
    "    \n",
    "        # Realizar la operaci√≥n deseada (ejemplo: suma de los embeddings)\n",
    "        resultado = similitud(row1['embeddings'] , row2['embeddings'])\n",
    "    \n",
    "            # Agregar los resultados al DataFrame de resultado\n",
    "        df_parcial = df_parcial.append({\n",
    "        'path1': path1,\n",
    "        'path2': path2,\n",
    "        'resultado': resultado\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        if len(df_parcial)>1000:\n",
    "            df_ordenado = df_parcial.sort_values(by='resultado', ascending=False)\n",
    "            df_parcial = df_ordenado.head(10)\n",
    "\n",
    "    #para cada identidad solo cogemos las 10 im√°genes que m√°s se le parecen     \n",
    "    df_ordenado = df_parcial.sort_values(by='resultado', ascending=False)\n",
    "    df_resultado = df_resultado.append(df_ordenado.head(10), ignore_index=True)\n",
    "    df_resultado.to_pickle(os.path.join(output_dir,'diferente_identidad.pkl'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado.to_excel(os.path.join(output_dir,'diferente_identidad_0.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado = pd.read_pickle(os.path.join(output_dir,'diferente_identidad.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_resultado):\n",
    "    df_resultado.to_pickle(os.path.join(output_dir,'diferente_identidad.pkl'))\n",
    "    df_resultado.to_excel(os.path.join(output_dir,'diferente_identidad.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(identities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lr-video",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae0b102d19e51505dfa7f9c4c891943d4814851bfb0fb9ee13b9b1dd2d5eef8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

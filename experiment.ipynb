{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations, product"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set dataset parameters\n",
    "Choose the attributes to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "detector = 'mtcnn_serfiq'  # ,'dlib', 'opencv', 'mediapipe','mtcnn','mtcnn_serfiq'\n",
    "embedding_model = 'QMagFace'  # 'QMagFace', 'QMagFace_SR',\"ArcFace\",\"Dlib\", 'VGG-Face','FaceVACs', 'Facenet512','ArcFace_normalized'\n",
    "\n",
    "#quality_models = ['ser_fiq'] #  'ser_fiq','tface'\n",
    "#embedding_models = ['Facenet512','QMagFace','ArcFace'] \n",
    "#quality_models = ['ser_fiq','tface']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set LR parameters\n",
    "Calibration, image filters, face filters, quality filters..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrators = ['logit']  # 'KDE', , 'isotonic','logit'\n",
    "\n",
    "#calibration_db0 = ['XQLFW','SCFace'] # \"SCFace\",'ForenFace','ENFSI','ForenFace','LFW','SCFace','UTKface','XQLFW',\n",
    "#image_filters0 = ['yaw', 'gender', 'race','emotion']   # 'yaw','pitch','roll', E.g. 'pose','gender','emotion','race'\n",
    "\n",
    "calibration_db = ['XQLFW'] # \"SCFace\",'ForenFace','ENFSI','ForenFace','LFW','SCFace','UTKface','XQLFW','UTKface','ENFSI',\n",
    "#'XQLFW','UTKface',\"SCFace\",'ForenFace',\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = 'euclidean_l2'\n",
    "embedding_model_as_scorer = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input and output directories\n",
    "Where the sql database is and which folder the results are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.path.expanduser(\"~\")\n",
    "\n",
    "# SQL database path and name\n",
    "input_dir = os.path.join(home, 'video_resources', 'sql_database')\n",
    "db_name = 'colab_main_dataset_21b'\n",
    "\n",
    "# Where results are saved\n",
    "output_dir = os.path.join(home, 'video_resources', 'experiment')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data\n",
    "Connect to sql database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 16:02:30.963783: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sql_face.alchemy import get_session\n",
    "from sql_face.tables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "session = get_session(input_dir, db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('data2.db','wb') as outp:\n",
    "#     pickle.dump(global_results,outp,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = session.query(Image,FaceImage) \\\n",
    ".select_from(Image).filter(Image.source == 'XQLFW') \\\n",
    ".join(CroppedImage).join(Detector).filter(Detector.name == detector) \\\n",
    ".join(FaceImage).join(EmbeddingModel).filter(EmbeddingModel.name == embedding_model).all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo el dataframe con los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cols = ['identity',  'path' , 'image_id']\n",
    "fi_cols = ['embeddings']\n",
    "#fixed_cols = ['Detector','E_Model','Q_Model','Q_group','Quality']\n",
    "\n",
    "df1 = pd.DataFrame([ [getattr(r[0],attr)   for attr in im_cols]  + [r[1].embeddings]\n",
    "                   for r in results1],\n",
    "                   columns=im_cols + fi_cols )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df1):\n",
    "    df1.to_pickle(os.path.join(output_dir,'imagenes.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1078, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 297, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\n",
      "  File \"/home/jmacarulla/anaconda3/envs/lr-video/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 1976, in do_wait_suspend\n",
      "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
      "  File \"/home/jmacarulla/anaconda3/envs/lr-video/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2011, in _do_wait_suspend\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jmacarulla/lr-video-face/experiment.ipynb Cell 20\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jmacarulla/lr-video-face/experiment.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m identities \u001b[39m=\u001b[39m \u001b[39mset\u001b[39;49m(df1\u001b[39m.\u001b[39midentity)\n",
      "\u001b[1;32m/home/jmacarulla/lr-video-face/experiment.ipynb Cell 20\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jmacarulla/lr-video-face/experiment.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m identities \u001b[39m=\u001b[39m \u001b[39mset\u001b[39;49m(df1\u001b[39m.\u001b[39midentity)\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1363\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:662\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1087\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1078\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:297\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/lr-video/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:1976\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   1973\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   1975\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001b[0;32m-> 1976\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   1978\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   1981\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/lr-video/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2011\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_mpl_hook()\n\u001b[1;32m   2010\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2011\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   2013\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2015\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "identities = set(df1.identity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defino la funcion de distancia o similitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hago la funcion coseno por hacer una\n",
    "def similitud(a,b):\n",
    "    a1 = np.array(a)\n",
    "    b1 = np.array(b)\n",
    "\n",
    "    return( np.dot(a1,b1)/(np.linalg.norm(a1)*np.linalg.norm(b1)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscar dentro de la misma identidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado = pd.DataFrame(columns=['path1', 'path2', 'resultado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identities = set(df1.identity)\n",
    "identities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for identity in tqdm(identities) :\n",
    "    dfx = df1.loc[(df1.identity == identity)]\n",
    "    if len(dfx) > 1:\n",
    "        combinaciones = list(combinations(dfx.iterrows(), 2))\n",
    "\n",
    "        # Iterar sobre las combinaciones\n",
    "        for comb in tqdm(combinaciones):\n",
    "            index1, row1 = comb[0]\n",
    "            index2, row2 = comb[1]\n",
    "    \n",
    "            path1 = row1['path']\n",
    "            path2 = row2['path']\n",
    "    \n",
    "            # Realizar la operación deseada (ejemplo: suma de los embeddings)\n",
    "            resultado = similitud(row1['embeddings'] , row2['embeddings'])\n",
    "    \n",
    "            # Agregar los resultados al DataFrame de resultado\n",
    "            df_resultado = df_resultado.append({\n",
    "            'path1': path1,\n",
    "            'path2': path2,\n",
    "            'resultado': resultado\n",
    "            }, ignore_index=True)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_resultado):\n",
    "    df_resultado.to_pickle(os.path.join(output_dir,'misma_identidad.pkl'))\n",
    "    df_resultado.to_excel(os.path.join(output_dir,'misma_identidad.xlsx'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscar en diferentes identidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identities = list(set(df1.identity))\n",
    "#identities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado = pd.DataFrame(columns=['path1', 'path2', 'resultado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,identity in enumerate(identities):\n",
    "    print(i)\n",
    "    dfx = df1.loc[(df1.identity == identity)]\n",
    "    dfy = df1.loc[(df1.identity > identity)]\n",
    "    \n",
    "    combinaciones = list(product(dfx.iterrows(), dfy.iterrows()))\n",
    "\n",
    "        # Iterar sobre las combinaciones\n",
    "    df_parcial = pd.DataFrame(columns=['path1', 'path2', 'resultado'])\n",
    "    for comb in tqdm(combinaciones):\n",
    "        \n",
    "        index1, row1 = comb[0]\n",
    "        index2, row2 = comb[1]\n",
    "    \n",
    "        path1 = row1['path']\n",
    "        path2 = row2['path']\n",
    "    \n",
    "        # Realizar la operación deseada (ejemplo: suma de los embeddings)\n",
    "        resultado = similitud(row1['embeddings'] , row2['embeddings'])\n",
    "    \n",
    "            # Agregar los resultados al DataFrame de resultado\n",
    "        df_parcial = df_parcial.append({\n",
    "        'path1': path1,\n",
    "        'path2': path2,\n",
    "        'resultado': resultado\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        if len(df_parcial)>1000:\n",
    "            df_ordenado = df_parcial.sort_values(by='resultado', ascending=False)\n",
    "            df_parcial = df_ordenado.head(10)\n",
    "\n",
    "    #para cada identidad solo cogemos las 10 imágenes que más se le parecen     \n",
    "    df_ordenado = df_parcial.sort_values(by='resultado', ascending=False)\n",
    "    df_resultado = df_resultado.append(df_ordenado.head(10), ignore_index=True)\n",
    "    df_resultado.to_pickle(os.path.join(output_dir,'diferente_identidad.pkl'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado.to_excel(os.path.join(output_dir,'diferente_identidad_0.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado = pd.read_pickle(os.path.join(output_dir,'diferente_identidad.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_resultado):\n",
    "    df_resultado.to_pickle(os.path.join(output_dir,'diferente_identidad.pkl'))\n",
    "    df_resultado.to_excel(os.path.join(output_dir,'diferente_identidad.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(identities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lr-video",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae0b102d19e51505dfa7f9c4c891943d4814851bfb0fb9ee13b9b1dd2d5eef8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

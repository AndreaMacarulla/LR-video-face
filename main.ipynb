{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set dataset parameters\n",
    "Choose the attributes to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors = ['mtcnn']  # 'dlib', 'opencv',\n",
    "embedding_models = ['ArcFace']  # \"Dlib\", 'VGG-Face','FaceVACs', 'Facenet512'\n",
    "# TODO:add quality models to experiments\n",
    "# quality_models = ['ser_fiq', 'tface']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set LR parameters\n",
    "Calibration, image filters, face filters, quality filters..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrators = ['logit', 'KDE']  # 'KDE', , 'isotonic'\n",
    "calibration_db = [\"LFW\", \"SCFace\"] # which datasets using to calibrate\n",
    "filters = []  # todo: change name to image filters. E.g. 'pose'\n",
    "face_image_filters = []  # 'confusion_score','quality'\n",
    "\n",
    "n_calibration_pairs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "enfsi_years = [2011, 2012]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other parameters\n",
    "Rest of the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = \"cosine\"\n",
    "embedding_model_as_scorer = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenarios\n",
    "Different filters to do computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario0 = []\n",
    "scenario1 = ['gender', 'age']\n",
    "scenario2 = ['yaw', 'pitch']\n",
    "scenario3 = ['glasses', 'beard']\n",
    "scenario4 = ['low_quality']\n",
    "scenario5 = ['headgear']\n",
    "scenario6 = ['terhorst_quality_rounded']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input and output directories\n",
    "Where the sql database is and which folder the results are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.path.expanduser(\"~\")\n",
    "\n",
    "# SQL database path and name\n",
    "input_dir = os.path.join(home, 'video_resources', 'sql_database')\n",
    "db_name = 'colab_main_dataset'\n",
    "\n",
    "# Where results are saved\n",
    "output_dir = os.path.join(home, 'video_resources', 'exp_output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data\n",
    "Connect to sql database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 20:37:27.558563: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 20:37:28.366661: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/andrea/anaconda3/envs/lr-video/lib/python3.8/site-packages/cv2/../../lib64:/home/andrea/Documents/cuda_software/cuda/lib64:/usr/local/cuda-11.2/lib64\n",
      "2022-12-12 20:37:28.366727: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/andrea/anaconda3/envs/lr-video/lib/python3.8/site-packages/cv2/../../lib64:/home/andrea/Documents/cuda_software/cuda/lib64:/usr/local/cuda-11.2/lib64\n",
      "2022-12-12 20:37:28.366742: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from sql_face.alchemy import get_session\n",
    "from sql_face.tables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = get_session(input_dir, db_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start experiments\n",
    "\n",
    "All parameters are specified in ExperimentalSetup, that creates a different experiment with all the posible combinations of detectors, embedding_models, calibrators, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr_video_face.experiments import ExperimentalSetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_setup = ExperimentalSetup(detectors, \n",
    "                                        embedding_models, \n",
    "                                        calibrators, \n",
    "                                        calibration_db, \n",
    "                                        enfsi_years,\n",
    "                                        filters, \n",
    "                                        face_image_filters, \n",
    "                                        metrics, \n",
    "                                        n_calibration_pairs,\n",
    "                                        embedding_model_as_scorer,\n",
    "                                        output_dir,\n",
    "                                        session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detectors': ['mtcnn'],\n",
       " 'embeddingModels': ['ArcFace'],\n",
       " 'calibrators': [LogitCalibrator(), KDECalibrator(bandwidth=(None, None))],\n",
       " 'calibration_db': ['LFW', 'SCFace'],\n",
       " 'enfsi_years': [2011, 2012],\n",
       " 'filters': [],\n",
       " 'face_image_filters': [],\n",
       " 'metrics': 'cosine',\n",
       " 'n_calibration_pairs': 100,\n",
       " 'embedding_model_as_scorer': True,\n",
       " 'session': <sqlalchemy.orm.session.Session at 0x7ff487e90190>,\n",
       " 'name': '2022-12-12 20 37 31',\n",
       " 'output_dir': '/home/andrea/video_resources/exp_output/C_(100)_[LFW,SCFace]_T_[                2011,2012]/[]',\n",
       " 'experiments': [<lr_video_face.experiments.Experiment at 0x7ff48517a220>,\n",
       "  <lr_video_face.experiments.Experiment at 0x7ff48517a250>],\n",
       " 'cllr_expert_per_year': defaultdict(list,\n",
       "             {2011: [0.4941270736033566,\n",
       "               0.5492113001744969,\n",
       "               0.7026598290722597,\n",
       "               0.2607763102785555,\n",
       "               0.16592504925773438,\n",
       "               0.363216659696734,\n",
       "               0.37984499769488217,\n",
       "               0.35379794879511217,\n",
       "               0.3695096638501844,\n",
       "               0.40513490282853726,\n",
       "               0.2802423334016544,\n",
       "               0.2888802337646105,\n",
       "               0.4501583642985826,\n",
       "               0.6676425434942473,\n",
       "               0.3235071422697966,\n",
       "               0.4200711423178839,\n",
       "               0.30831135042199537],\n",
       "              2012: [1.7027267497901453,\n",
       "               0.6544320160440226,\n",
       "               0.9106621027904607,\n",
       "               0.8109172880022706,\n",
       "               0.8924073840228437,\n",
       "               0.49029684770271353,\n",
       "               1.144602451504906,\n",
       "               0.9041587012180243,\n",
       "               0.8631672080941745]})}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimental_setup.__dict__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('lr-video')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c08d8fec19e509e399d6ec1cb9b529f9385c45181b63bf2f2d9547e2a9a7b9b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairing\n",
    "\n",
    "> Functions to do the test pairings and video pairings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from itertools import islice\n",
    "\n",
    "from sqlalchemy.orm import aliased\n",
    "from collections import defaultdict\n",
    "\n",
    "from sql_face.tables import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_test_pairs(enfsi_years, session):\n",
    "\n",
    "       test_pairs = (session.query(EnfsiPair)\n",
    "                     .filter(EnfsiPair.second.has(EnfsiImage.year.in_(enfsi_years)))\n",
    "                     .all()\n",
    "                     )\n",
    "       return test_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_valid_test_pairs_2015(session, \n",
    "                        detector,\n",
    "                        embeddingModel,\n",
    "                        qualityModel,\n",
    "                        quality_dropouts)->Tuple[EnfsiPair2015, FaceImage, FaceImage, float]:\n",
    "\n",
    "    \n",
    "    # todo: alias not needed anymore. Remove them.\n",
    "    first_cropped_image = aliased(CroppedImage)\n",
    "    second_cropped_image = aliased(CroppedImage)\n",
    "    first_detector = aliased(Detector)\n",
    "    second_detector = aliased(Detector)\n",
    "    first_face_image = aliased(FaceImage)\n",
    "    second_face_image = aliased(FaceImage)\n",
    "    first_emb = aliased(EmbeddingModel)\n",
    "    second_emb = aliased(EmbeddingModel)\n",
    "    first_qua = aliased(QualityModel)\n",
    "    second_qua = aliased(QualityModel)\n",
    "\n",
    "    # Det&Emb\n",
    "    det_id = session.query(Detector.detector_id).filter(Detector.name == detector).one()[0]\n",
    "    emb_id = \\\n",
    "    session.query(EmbeddingModel.embeddingModel_id).filter(EmbeddingModel.name == embeddingModel).one()[0]\n",
    "    qua_id = \\\n",
    "    session.query(QualityModel.qualityModel_id).filter(QualityModel.name == qualityModel).one()[0]\n",
    "\n",
    "    \n",
    "    query_face_img_id = session.query(CroppedImage.image_id, FaceImage, QualityImage.quality) \\\n",
    "        .filter(CroppedImage.detector_id == det_id, CroppedImage.face_detected == True) \\\n",
    "        .filter(FaceImage.croppedImage_id == CroppedImage.croppedImage_id) \\\n",
    "        .filter(FaceImage.embeddingModel_id == emb_id) \\\n",
    "        .filter(QualityImage.faceImage_id == FaceImage.faceImage_id) \\\n",
    "        .filter(QualityImage.qualityModel_id == qua_id).all()\n",
    "\n",
    "    # a cada image_id asociamos su (FaceImage,  quality)\n",
    "    face_image_dict = defaultdict(Tuple)\n",
    "    for row in query_face_img_id:\n",
    "        face_image_dict[row[0]] = (row[1], row[2]) \n",
    "\n",
    "    \n",
    "    subquery_pair = session.query(EnfsiPair2015.enfsiPair2015_id)\\\n",
    "        .join(first_cropped_image, EnfsiPair2015.first_id == first_cropped_image.image_id) \\\n",
    "        .filter(first_cropped_image.detector_id == det_id,\n",
    "                first_cropped_image.face_detected == True).subquery()\n",
    "\n",
    "\n",
    "    query_pair = session.query(EnfsiPair2015) \\\n",
    "        .join(second_cropped_image, EnfsiPair2015.second_id == second_cropped_image.image_id) \\\n",
    "        .filter(second_cropped_image.detector_id == det_id,\n",
    "                second_cropped_image.face_detected == True,\n",
    "                EnfsiPair2015.enfsiPair2015_id.in_(subquery_pair))\n",
    "\n",
    "    \n",
    "    all_pairs = query_pair.all()\n",
    "\n",
    "    comparisons = list(set([enfsi_pair.comparison for enfsi_pair in all_pairs]))\n",
    "\n",
    "    best_pairs = []\n",
    "\n",
    "    # imagen promedio por comparison, no existe en Database\n",
    "    df_mean_image = pd.DataFrame(columns = ['Comparison','embedding1','embedding2', 'y'])\n",
    "    \n",
    "    for x in comparisons:\n",
    "\n",
    "        comp_pairs = [(pair, min(face_image_dict[pair.first.image_id][1], face_image_dict[pair.second.image_id][1])) \\\n",
    "            for pair in all_pairs if pair.comparison == x]\n",
    "\n",
    "        \n",
    "        comp_pairs.sort(key=lambda x:x[1], reverse=True)\n",
    "        qua_pairs = [comp_pair[0] for comp_pair in comp_pairs]\n",
    "\n",
    "        for dropout in quality_dropouts:\n",
    "            # best_pairs+=comp_pairs[:int(len(comp_pairs)*dropout)]\n",
    "            truncated_pairs = list(islice(qua_pairs, math.ceil(len(qua_pairs) * dropout)))\n",
    "            drop_pairs = [(pair, dropout) for pair in truncated_pairs]\n",
    "            best_pairs += drop_pairs\n",
    "\n",
    "\n",
    "\n",
    "        emb1  = [face_image_dict[pair[0].first.image_id][0].embeddings for pair in comp_pairs]\n",
    "        weight1 = [face_image_dict[pair[0].first.image_id][1] for pair in comp_pairs]\n",
    "        embedding_first = np.dot(weight1,emb1)/np.sum(weight1)\n",
    "\n",
    "        emb2  = [face_image_dict[pair[0].second.image_id][0].embeddings for pair in comp_pairs]\n",
    "        weight2 = [face_image_dict[pair[0].second.image_id][1] for pair in comp_pairs]\n",
    "        embedding_second = np.dot(weight2,emb2)/np.sum(weight2)\n",
    "\n",
    "        y = comp_pairs[0][0].same\n",
    "\n",
    "        df_mean_image = df_mean_image.append({'Comparison':x,'embedding1':embedding_first,'embedding2':embedding_second, 'y':y}, ignore_index = True)\n",
    "\n",
    "        #emb1 ,weigth2 = [face_image_dict[pair.second.image_id][0].embeddings, face_image_dict[pair.second.image_id][1] for pair in comp_pairs]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    valid_test_pairs = [(pair[0], face_image_dict[pair[0].first.image_id][0],\\\n",
    "                        face_image_dict[pair[0].second.image_id][0], pair[1],pair[0].get_n_common_attributes())\n",
    "                        for pair in best_pairs] #(pair, emb1,emb2,quality_drop,n_common_attributes)\n",
    "    \n",
    "    return valid_test_pairs, df_mean_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_valid_test_pairs(session, \n",
    "                        detector,\n",
    "                        embeddingModel,\n",
    "                        enfsi_years) -> Tuple[EnfsiPair, FaceImage, FaceImage]:\n",
    "\n",
    "    first_cropped_image = aliased(CroppedImage)\n",
    "    second_cropped_image = aliased(CroppedImage)\n",
    "    first_detector = aliased(Detector)\n",
    "    second_detector = aliased(Detector)\n",
    "    first_face_image = aliased(FaceImage)\n",
    "    second_face_image = aliased(FaceImage)\n",
    "    first_emb = aliased(EmbeddingModel)\n",
    "    second_emb = aliased(EmbeddingModel)\n",
    "\n",
    "    # Det&Emb\n",
    "    det_id = session.query(Detector.detector_id).filter(Detector.name == detector).one()[0]\n",
    "    emb_id = \\\n",
    "    session.query(EmbeddingModel.embeddingModel_id).filter(EmbeddingModel.name == embeddingModel).one()[0]\n",
    "\n",
    "    query_face_img_id = session.query(CroppedImage.image_id, FaceImage) \\\n",
    "        .filter(CroppedImage.detector_id == det_id, CroppedImage.face_detected == True) \\\n",
    "        .filter(FaceImage.croppedImage_id == CroppedImage.croppedImage_id) \\\n",
    "        .filter(FaceImage.embeddingModel_id == emb_id).all()\n",
    "\n",
    "    face_image_dict = defaultdict(FaceImage)\n",
    "    for row in query_face_img_id:\n",
    "        face_image_dict[row[0]] = row[1]\n",
    "\n",
    "    query_pair_id = session.query(EnfsiPair).filter(EnfsiPair.second.has(EnfsiImage.year.in_(enfsi_years)))\n",
    "\n",
    "    query_1 = query_pair_id \\\n",
    "        .join(first_cropped_image, EnfsiPair.first_id == first_cropped_image.image_id) \\\n",
    "        .filter(first_cropped_image.detector_id == det_id,\n",
    "                first_cropped_image.face_detected == True)\n",
    "\n",
    "    query_2 = query_pair_id \\\n",
    "        .join(second_cropped_image, EnfsiPair.second_id == second_cropped_image.image_id) \\\n",
    "        .filter(second_cropped_image.detector_id == det_id,\n",
    "                second_cropped_image.face_detected == True)\n",
    "\n",
    "    query = (query_1.intersect(query_2).all())\n",
    "\n",
    "    # The one at the end indicates all the pairs are chosen (see year 2015).\n",
    "    valid_test_pairs = [(pair, face_image_dict[pair.first.image_id],\\\n",
    "                        face_image_dict[pair.second.image_id], 1, pair.get_n_common_attributes())\n",
    "                        for pair in query]\n",
    "    \n",
    "    return valid_test_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_test_pairs_per_category(session,\n",
    "                                #new\n",
    "                                #image_filters,\n",
    "                                #face_image_filters,\n",
    "                                filters,\n",
    "\n",
    "                                detector,\n",
    "                                embeddingModel,\n",
    "                                qualityModel,\n",
    "                                enfsi_years,\n",
    "                                quality_dropout):\n",
    "\n",
    "    valid_test_pairs = []\n",
    "    df_pairs_2015 = None\n",
    "    \n",
    "    enfsi_short = enfsi_years.copy()\n",
    "    \n",
    "    if 2015 in enfsi_years:\n",
    "\n",
    "        enfsi_short.remove(2015)\n",
    "        valid_test_pairs, df_pairs_2015 = get_valid_test_pairs_2015(session,\n",
    "                                            detector,\n",
    "                                            embeddingModel,\n",
    "                                            qualityModel,\n",
    "                                            quality_dropout)\n",
    "        \n",
    "        \n",
    "    valid_test_pairs += get_valid_test_pairs(session,\n",
    "                                            detector,\n",
    "                                            embeddingModel,\n",
    "                                            #qualityModel,\n",
    "                                            enfsi_short) \n",
    "    #quitado para 2015\n",
    "    \n",
    "\n",
    "    test_categories = [\n",
    "        row[0].get_category(session, filters, detector, embeddingModel, qualityModel)\n",
    "        #row[0].get_category(image_filters, face_image_filters, detector, embeddingModel)\n",
    "        for row in valid_test_pairs]\n",
    "\n",
    "    test_pairs_per_category = defaultdict(list)\n",
    "\n",
    "    for row_enfsi_pair, category in zip(valid_test_pairs, test_categories):\n",
    "        test_pairs_per_category[category].append(row_enfsi_pair)\n",
    "    return test_pairs_per_category, df_pairs_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lr-video",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

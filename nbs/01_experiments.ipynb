{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiments\n",
    "\n",
    "> Where the set of experiments and the single experiments are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "import os\n",
    "import lir\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from typing import List, Iterator, Dict, Union, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from lir import (LogitCalibrator,\n",
    "                 NormalizedCalibrator,\n",
    "                 ELUBbounder,\n",
    "                 KDECalibrator,\n",
    "                 FractionCalibrator,\n",
    "                 IsotonicCalibrator,\n",
    "                 DummyCalibrator, Xy_to_Xn)\n",
    "\n",
    "from sql_face.tables import EnfsiImage, EnfsiPair\n",
    "from lr_video_face.calibration import ScorerModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "One single expleriment defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Experiment:\n",
    "\n",
    "    def __init__(self,\n",
    "        detector: str,\n",
    "        embeddingModel: str,\n",
    "        scorer: BaseEstimator,\n",
    "        calibrator: BaseEstimator,\n",
    "        calibration_db: List[str],\n",
    "        enfsi_years: List[int],\n",
    "        filters: List[str],\n",
    "        face_image_filters: List[str],\n",
    "        metrics: str,\n",
    "        n_calibration_pairs: int,\n",
    "        embedding_model_as_scorer: bool,\n",
    "        root_output_dir: str\n",
    "        ):     \n",
    "    \n",
    "    \n",
    "\n",
    "        self.detector = detector\n",
    "        self.embeddingModel = embeddingModel\n",
    "        self.scorer = scorer\n",
    "        self.calibrator = calibrator\n",
    "        self.calibration_db = calibration_db\n",
    "        self.enfsi_years = enfsi_years\n",
    "        self.filters = filters\n",
    "        self.face_image_filters = face_image_filters\n",
    "        self.metrics = metrics\n",
    "        self.n_calibration_pairs = n_calibration_pairs\n",
    "        self.embedding_model_as_scorer = embedding_model_as_scorer\n",
    "        self.root_output_dir = root_output_dir\n",
    "        self.output_dir = self._get_output_dir()\n",
    "\n",
    "\n",
    "    def _get_output_dir(self):\n",
    "        if isinstance(self.calibrator, IsotonicCalibrator):\n",
    "            calibrator = 'Isotonic Calibrator'\n",
    "        else:\n",
    "            calibrator = str(self.calibrator)\n",
    "\n",
    "        if self.embedding_model_as_scorer:\n",
    "            folder = f'{self.detector}_{self.embeddingModel}(emb=scorer)_{calibrator.split(\"(\")[0]}'\n",
    "        else:\n",
    "            folder = f'{self.detector}_{self.embeddingModel}(emb<>scorer)_{calibrator.split(\"(\")[0]}'\n",
    "\n",
    "        output_dir = os.path.join(self.root_output_dir, folder)\n",
    "        return output_dir\n",
    "    \n",
    "    \n",
    "    def perform(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Function to run a single experiment with pipeline:\n",
    "        - Fit model on train data\n",
    "        - Fit calibrator on calibrator data\n",
    "        - Evaluate test set\n",
    "        \"\"\"\n",
    "\n",
    "        # Create folder\n",
    "        self.create_output_dir()\n",
    "        session = connect_db()\n",
    "\n",
    "        # Get test pairs per category.\n",
    "        test_pairs_per_category = self.get_test_pairs_per_category(session)\n",
    "        # Get calibration pair per category.\n",
    "        calibration_pairs_per_category = self.get_calibration_pairs_per_category(test_pairs_per_category.keys(),\n",
    "                                                                                 session)\n",
    "        '''\n",
    "        # todo: move later.\n",
    "        pairs_df = pd.DataFrame(columns=['Image 1', 'Image 2'])\n",
    "        for category, pairs in calibration_pairs_per_category.items():\n",
    "            print(category, len(pairs))\n",
    "            for pair in pairs:\n",
    "                pairs_df = pairs_df.append({'Image 1': pair.first.croppedImages.images.path, 'Image 2': pair.second.croppedImages.images.path}, ignore_index=True)\n",
    "\n",
    "        pairs_df.to_excel(f'cal_pairs_{self.filters}_{self.face_image_filters}.xlsx')\n",
    "        '''\n",
    "\n",
    "        # Generate lr_system per category.\n",
    "        lr_systems, test_pairs_per_category = self.generate_lr_systems(calibration_pairs_per_category,\n",
    "                                                                       test_pairs_per_category, session)\n",
    "\n",
    "        # Predict LR\n",
    "        results = self.predict_lr(lr_systems, test_pairs_per_category, session)\n",
    "\n",
    "        # todo: make necessary variables for graphs.\n",
    "        return results\n",
    "\n",
    "   \n",
    "    def create_output_dir(self):\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Converts the configuration of this experiment to a string that can be\n",
    "        used to generate file names for example.\n",
    "        \"\"\"\n",
    "        data_values = []\n",
    "        for k, v in self.data_config.items():\n",
    "            if k == 'datasets' and isinstance(v, tuple):\n",
    "                data_values.append('|'.join(map(str, v)))\n",
    "            else:\n",
    "                data_values.append(str(v))\n",
    "\n",
    "        params_str = '_'.join(map(str, self.params.values()))\n",
    "        return '_'.join(map(str, [\n",
    "            self.scorer,\n",
    "            self.calibrator,\n",
    "            params_str\n",
    "        ])).replace(':', '-')  # Windows forbids ':'\n",
    "\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Setup\n",
    "The set of all experiments for one scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ExperimentalSetup:\n",
    "    def __init__(self, \n",
    "                detectors, \n",
    "                embeddingModels, \n",
    "                calibrator_names, \n",
    "                calibration_db, \n",
    "                enfsi_years, \n",
    "                filters, \n",
    "                face_image_filters,\n",
    "                metrics, \n",
    "                n_calibration_pairs, \n",
    "                embedding_model_as_scorer,\n",
    "                results_folder:str,\n",
    "                session,\n",
    "                name:datetime = datetime.now().strftime(\"%Y-%m-%d %H %M %S\")\n",
    "                ):\n",
    "\n",
    "        self.detectors = detectors\n",
    "        self.embeddingModels = embeddingModels\n",
    "        self.calibrators = self._get_calibrators(calibrator_names)\n",
    "        self.calibration_db = calibration_db\n",
    "        self.enfsi_years = enfsi_years\n",
    "        self.filters = filters\n",
    "        self.face_image_filters = face_image_filters\n",
    "        self.metrics = metrics\n",
    "        self.n_calibration_pairs = n_calibration_pairs\n",
    "        self.embedding_model_as_scorer = embedding_model_as_scorer\n",
    "        self.session = session\n",
    "        self.name = datetime.now().strftime(\"%Y-%m-%d %H %M %S\")\n",
    "        self.output_dir= self._make_output_dir(results_folder)\n",
    "        self.experiments = self.prepare_experiments()\n",
    "        self.cllr_expert_per_year = self._get_cllr_expert_per_year()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_calibrators(calibrator_names: List[str]) \\\n",
    "            -> List[BaseEstimator]:\n",
    "        \"\"\"\n",
    "        Parses a list of CALIBRATORS configuration names and returns the\n",
    "        corresponding calibrators. \n",
    "        :param calibrator_names: List[str]\n",
    "        :return: List[ScorerModel]\n",
    "        \"\"\"\n",
    "        CALIBRATORS = {\n",
    "            'logit': LogitCalibrator(),\n",
    "            'logit_normalized': NormalizedCalibrator(LogitCalibrator()),\n",
    "            'KDE': KDECalibrator(),\n",
    "            'elub_KDE': ELUBbounder(KDECalibrator()),\n",
    "            'fraction': FractionCalibrator(),\n",
    "            'isotonic': IsotonicCalibrator(add_misleading=1)\n",
    "        }  \n",
    "        # todo: isotonic needs repr method. Could create an instance with one.\n",
    "        return [CALIBRATORS[c] for c in calibrator_names]\n",
    "\n",
    "    \n",
    "    def _get_directory(self):\n",
    "        filters = self.filters + self.face_image_filters\n",
    "        subfolder = f'[{\",\".join(filters)}]'\n",
    "        folder = f'C_({self.n_calibration_pairs})_[{\",\".join(self.calibration_db)}]_T_[\\\n",
    "                {\",\".join([str(year) for year in self.enfsi_years])}]'\n",
    "        return os.path.join(folder, subfolder)\n",
    "\n",
    "    def _make_output_dir(self, results_folder):\n",
    "        directory = self._get_directory()\n",
    "        output_dir = os.path.join(results_folder, directory)\n",
    "        if not os.path.exists(results_folder):\n",
    "            os.makedirs(results_folder)\n",
    "        return output_dir\n",
    "\n",
    "    # def __post_init__(self):\n",
    "    #     self.calibrators = self._get_calibrators(self.calibrator_names)\n",
    "    #     self.output_dir: str = self.make_output_dir()\n",
    "    #     \n",
    "\n",
    "     \n",
    "    def _get_cllr_expert_per_year(self):\n",
    "        session = self.session\n",
    "        expert_eval = session.query(EnfsiImage.year, EnfsiPair.same, EnfsiPair.ExpertsLLR) \\\n",
    "            .filter(EnfsiImage.image_id == EnfsiPair.second_id,\n",
    "                    EnfsiImage.year.in_(self.enfsi_years)) \\\n",
    "            .all()        \n",
    "\n",
    "        y_test_per_year = defaultdict(list)\n",
    "        LLR_experts_per_year = defaultdict(list)\n",
    "\n",
    "        for year, y, LLR_expert in expert_eval:\n",
    "            y_test_per_year[year].append(y)\n",
    "            LLR_experts_per_year[year].append(LLR_expert)\n",
    "\n",
    "        cllr_experts_per_year = defaultdict(list)\n",
    "\n",
    "        for year in self.enfsi_years:\n",
    "            LLR_experts = np.asarray(LLR_experts_per_year[year])\n",
    "            for i, expert in enumerate(LLR_experts.T):\n",
    "                # todo: overflow bug with np.power(10, expert) for year 2017.\n",
    "                LR_expert = np.asarray([np.power(10, i) for i in expert])\n",
    "                cllr_expert = lir.metrics.cllr(LR_expert,\n",
    "                                               np.asarray(y_test_per_year[year]))\n",
    "                cllr_experts_per_year[year].append(cllr_expert)\n",
    "\n",
    "        return cllr_experts_per_year\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def prepare_experiments(self) -> List[Experiment]:\n",
    "        \"\"\"\n",
    "        Returns a list of all experiments that fall under this setup.\n",
    "\n",
    "        :return: List[Experiment]\n",
    "        \"\"\"\n",
    "        experiments = []\n",
    "        for detector in self.detectors:\n",
    "            for embeddingModel in self.embeddingModels:\n",
    "                for calibrator in self.calibrators:\n",
    "                    if self.embedding_model_as_scorer:\n",
    "                        scorer = ScorerModel(metric=self.metrics, embeddingModel=embeddingModel)\n",
    "                    else:\n",
    "                        scorer = LogisticRegression(solver='lbfgs')\n",
    "                    experiments.append(Experiment(\n",
    "                        detector,\n",
    "                        embeddingModel,\n",
    "                        scorer,\n",
    "                        calibrator,\n",
    "                        self.calibration_db,\n",
    "                        self.enfsi_years,\n",
    "                        self.filters,\n",
    "                        self.face_image_filters,\n",
    "                        self.metrics,\n",
    "                        self.n_calibration_pairs,\n",
    "                        self.embedding_model_as_scorer,\n",
    "                        self.output_dir\n",
    "                    ))\n",
    "\n",
    "        return experiments\n",
    "\n",
    "    def __iter__(self) -> Iterator[Experiment]:\n",
    "        return iter(self.experiments)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.experiments)\n",
    "\n",
    "   \n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "\n",
    "    # def count_detected_faces(self, output_dir):\n",
    "    #     session = connect_db()\n",
    "    #     all_faces = (session.query(EnfsiImage.year, Detector.name, CroppedImage.face_detected, func.count(\"*\")) \\\n",
    "    #                  .join(EnfsiImage)\n",
    "    #                  .join(Detector)\n",
    "    #                  .filter(EnfsiImage.year.in_(self.enfsi_years))\n",
    "    #                  .group_by(EnfsiImage.year, Detector.name, CroppedImage.face_detected)\n",
    "    #                  .all()\n",
    "    #                  )\n",
    "    #     detected_faces_df = pd.DataFrame.from_records(all_faces)\n",
    "    #     detected_faces_df.to_excel(os.path.join(output_dir, f'detected_faces.xlsx'))\n",
    "    #     session.close()\n",
    "\n",
    "   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lr-video",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

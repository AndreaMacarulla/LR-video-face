{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Experiment:\n",
    "\n",
    "    def __init__(self,\n",
    "        detector: str,\n",
    "        embeddingModel: str,\n",
    "        scorer: BaseEstimator,\n",
    "        calibrator: BaseEstimator,\n",
    "        calibration_db: List[str],\n",
    "        enfsi_years: List[int],\n",
    "        filters: List[str],\n",
    "        face_image_filters: List[str],\n",
    "        metrics: str,\n",
    "        n_calibration_pairs: int,\n",
    "        embedding_model_as_scorer: bool,\n",
    "        root_output_dir: str\n",
    "        ):\n",
    "\n",
    "        self.detector = detector\n",
    "        self.embeddingModel = embeddingModel\n",
    "        self.scorer = scorer\n",
    "        self.calibrator = calibrator\n",
    "        self.calibration_db = calibration_db\n",
    "        self.enfsi_years = enfsi_years\n",
    "        self.filters = filters\n",
    "        self.face_image_filters = face_image_filters\n",
    "        self.metrics = metrics\n",
    "        self.n_calibration_pairs = n_calibration_pairs\n",
    "        self.embedding_model_as_scorer = embedding_model_as_scorer\n",
    "        self.root_output_dir = root_output_dir\n",
    "        self.output_dir = get_output_dir()\n",
    "\n",
    "\n",
    "    def get_output_dir(self):\n",
    "        if isinstance(self.calibrator, IsotonicCalibrator):\n",
    "            calibrator = 'Isotonic Calibrator'\n",
    "        else:\n",
    "            calibrator = str(self.calibrator)\n",
    "\n",
    "        if self.embedding_model_as_scorer:\n",
    "            folder = f'{self.detector}_{self.embeddingModel}(emb=scorer)_{calibrator.split(\"(\")[0]}'\n",
    "        else:\n",
    "            folder = f'{self.detector}_{self.embeddingModel}(emb<>scorer)_{calibrator.split(\"(\")[0]}'\n",
    "\n",
    "        output_dir = os.path.join(self.root_output_dir, folder)\n",
    "        return output_dir\n",
    "    \n",
    "    \n",
    "    def perform(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Function to run a single experiment with pipeline:\n",
    "        - Fit model on train data\n",
    "        - Fit calibrator on calibrator data\n",
    "        - Evaluate test set\n",
    "        \"\"\"\n",
    "\n",
    "        # Create folder\n",
    "        self.create_output_dir()\n",
    "        session = connect_db()\n",
    "\n",
    "        # Get test pairs per category.\n",
    "        test_pairs_per_category = self.get_test_pairs_per_category(session)\n",
    "        # Get calibration pair per category.\n",
    "        calibration_pairs_per_category = self.get_calibration_pairs_per_category(test_pairs_per_category.keys(),\n",
    "                                                                                 session)\n",
    "        '''\n",
    "        # todo: move later.\n",
    "        pairs_df = pd.DataFrame(columns=['Image 1', 'Image 2'])\n",
    "        for category, pairs in calibration_pairs_per_category.items():\n",
    "            print(category, len(pairs))\n",
    "            for pair in pairs:\n",
    "                pairs_df = pairs_df.append({'Image 1': pair.first.croppedImages.images.path, 'Image 2': pair.second.croppedImages.images.path}, ignore_index=True)\n",
    "\n",
    "        pairs_df.to_excel(f'cal_pairs_{self.filters}_{self.face_image_filters}.xlsx')\n",
    "        '''\n",
    "\n",
    "        # Generate lr_system per category.\n",
    "        lr_systems, test_pairs_per_category = self.generate_lr_systems(calibration_pairs_per_category,\n",
    "                                                                       test_pairs_per_category, session)\n",
    "\n",
    "        # Predict LR\n",
    "        results = self.predict_lr(lr_systems, test_pairs_per_category, session)\n",
    "\n",
    "        # todo: make necessary variables for graphs.\n",
    "        return results\n",
    "\n",
    "    def get_test_pairs_per_category(self, session):\n",
    "\n",
    "        # t1 = time.process_time()\n",
    "        # test_pairs = self.get_test_pairs(session)\n",
    "        # valid_test_pairs = [pair for pair in test_pairs if pair.is_valid(self.detector)]\n",
    "        # elapsed_time_1 = time.process_time() - t1\n",
    "        # t2 = time.process_time()\n",
    "        # todo: improve efficiency.\n",
    "        valid_test_pairs = self.get_valid_test_pairs(session)\n",
    "        # elapsed_time_2 = time.process_time() - t2\n",
    "        # print(f'Old method is {elapsed_time_1}')\n",
    "        # print(f'New method is {elapsed_time_2}')\n",
    "        # test_categories = [\n",
    "        #    pair.get_category(self.filters, self.face_image_filters, self.detector, self.embeddingModel)\n",
    "        #    for pair in valid_test_pairs]\n",
    "\n",
    "        test_categories = [\n",
    "            row[0].get_category(self.filters, self.face_image_filters, self.detector, self.embeddingModel)\n",
    "            for row in valid_test_pairs]\n",
    "\n",
    "        test_pairs_per_category = defaultdict(list)\n",
    "        # for face_pair, category in zip(valid_test_pairs, test_categories):\n",
    "        #    test_pairs_per_category[category].append(face_pair)\n",
    "\n",
    "        for row_enfsi_pair, category in zip(valid_test_pairs, test_categories):\n",
    "            test_pairs_per_category[category].append(row_enfsi_pair)\n",
    "        return test_pairs_per_category\n",
    "\n",
    "    def get_test_pairs(self, session):\n",
    "\n",
    "        test_pairs = (session.query(EnfsiPair)\n",
    "                      .filter(EnfsiPair.second.has(EnfsiImage.year.in_(self.enfsi_years)))\n",
    "                      .all()\n",
    "                      )\n",
    "        return test_pairs\n",
    "\n",
    "    def get_valid_test_pairs(self, session) -> Tuple[EnfsiPair, FaceImage, FaceImage]:\n",
    "        first_cropped_image = aliased(CroppedImage)\n",
    "        second_cropped_image = aliased(CroppedImage)\n",
    "        first_detector = aliased(Detector)\n",
    "        second_detector = aliased(Detector)\n",
    "        first_face_image = aliased(FaceImage)\n",
    "        second_face_image = aliased(FaceImage)\n",
    "        first_emb = aliased(EmbeddingModel)\n",
    "        second_emb = aliased(EmbeddingModel)\n",
    "\n",
    "        # Det&Emb\n",
    "        det_id = session.query(Detector.detector_id).filter(Detector.name == self.detector).one()[0]\n",
    "        emb_id = \\\n",
    "        session.query(EmbeddingModel.embeddingModel_id).filter(EmbeddingModel.name == self.embeddingModel).one()[0]\n",
    "\n",
    "        query_face_img_id = session.query(CroppedImage.image_id, FaceImage) \\\n",
    "            .filter(CroppedImage.detector_id == det_id, CroppedImage.face_detected == True) \\\n",
    "            .filter(FaceImage.croppedImage_id == CroppedImage.croppedImage_id) \\\n",
    "            .filter(FaceImage.embeddingModel_id == emb_id).all()\n",
    "\n",
    "        face_image_dict = defaultdict(FaceImage)\n",
    "        for row in query_face_img_id:\n",
    "            face_image_dict[row[0]] = row[1]\n",
    "\n",
    "        query_pair_id = session.query(EnfsiPair).filter(EnfsiPair.second.has(EnfsiImage.year.in_(self.enfsi_years)))\n",
    "\n",
    "        query_1 = query_pair_id \\\n",
    "            .join(first_cropped_image, EnfsiPair.first_id == first_cropped_image.image_id) \\\n",
    "            .filter(first_cropped_image.detector_id == det_id,\n",
    "                    first_cropped_image.face_detected == True)\n",
    "\n",
    "        query_2 = query_pair_id \\\n",
    "            .join(second_cropped_image, EnfsiPair.second_id == second_cropped_image.image_id) \\\n",
    "            .filter(second_cropped_image.detector_id == det_id,\n",
    "                    second_cropped_image.face_detected == True)\n",
    "\n",
    "        query = (query_1.intersect(query_2).all())\n",
    "\n",
    "        valid_test_pairs = [(pair, face_image_dict[pair.first.image_id], face_image_dict[pair.second.image_id]) for pair\n",
    "                            in query]\n",
    "\n",
    "        # query_1 = session.query(EnfsiPair, first_face_image).filter(EnfsiPair.second.has(EnfsiImage.year.in_(self.enfsi_years)))\n",
    "        # query_2 = session.query(EnfsiPair, second_face_image).filter(EnfsiPair.second.has(EnfsiImage.year.in_(self.enfsi_years)))\n",
    "        #\n",
    "        # #Cropped Images\n",
    "        # query_1 = query_1 \\\n",
    "        #     .join(first_cropped_image, EnfsiPair.first_id == first_cropped_image.image_id) \\\n",
    "        #     .filter(first_cropped_image.detector_id == det_id,\n",
    "        #             first_cropped_image.face_detected == True)\n",
    "        #\n",
    "        # query_2 = query_2 \\\n",
    "        #     .join(second_cropped_image, EnfsiPair.second_id == second_cropped_image.image_id) \\\n",
    "        #     .filter(second_cropped_image.detector_id == det_id,\n",
    "        #             second_cropped_image.face_detected == True)\n",
    "        #\n",
    "        # # Face Images\n",
    "        # query_1 = query_1 \\\n",
    "        #     .join(first_face_image, first_cropped_image.croppedImage_id == first_face_image.croppedImage_id) \\\n",
    "        #     .filter(first_face_image.embeddingModel_id == emb_id)\n",
    "        #\n",
    "        # query_2 = query_2 \\\n",
    "        #     .join(second_face_image, second_cropped_image.croppedImage_id == second_face_image.croppedImage_id) \\\n",
    "        #     .filter(second_face_image.embeddingModel_id == emb_id)\n",
    "        #\n",
    "        # query_1_result = (query_1.all())\n",
    "        # query_2_result = (query_2.all())\n",
    "        # query = query_1[0].intersect(query_2[0]).all()\n",
    "        # # valid_test_pairs = (query.all())\n",
    "        return valid_test_pairs\n",
    "\n",
    "    def get_calibration_pairs_per_category(self, categories, session):\n",
    "        cal_face_pairs = {}\n",
    "        emb_facevacs = (self.embeddingModel == 'FaceVACs')\n",
    "\n",
    "        for pair_category in categories:\n",
    "\n",
    "            first_image_category = self.get_filtered_images(filter_values=pair_category[0], session=session)\n",
    "            if pair_category[0] == pair_category[1]:\n",
    "                if emb_facevacs:\n",
    "                    all_calibration_pairs = get_calibration_facepairs_facevacs(\n",
    "                        first_list_of_face_images=first_image_category,\n",
    "                        second_list_of_face_images=first_image_category,\n",
    "                        number_of_pairs=self.n_calibration_pairs,\n",
    "                        session=session\n",
    "                    )\n",
    "                else:\n",
    "                    all_calibration_pairs = make_cal_face_pairs(first_list_of_face_images=first_image_category,\n",
    "                                                                number_of_pairs=self.n_calibration_pairs)\n",
    "\n",
    "            else:\n",
    "                second_image_category = self.get_filtered_images(filter_values=pair_category[1],\n",
    "                                                                 session=session)\n",
    "                if emb_facevacs:\n",
    "                    all_calibration_pairs = get_calibration_facepairs_facevacs(\n",
    "                        first_list_of_face_images=first_image_category,\n",
    "                        second_list_of_face_images=second_image_category,\n",
    "                        number_of_pairs=self.n_calibration_pairs,\n",
    "                        session=session\n",
    "                    )\n",
    "                else:\n",
    "                    all_calibration_pairs = make_cal_face_pairs(first_list_of_face_images=first_image_category,\n",
    "                                                                second_list_of_face_images=second_image_category,\n",
    "                                                                number_of_pairs=self.n_calibration_pairs)\n",
    "            cal_face_pairs[pair_category] = all_calibration_pairs\n",
    "        return cal_face_pairs\n",
    "\n",
    "    def get_filtered_images(self, filter_values: tuple, session):\n",
    "        im_filter_values = filter_values[:len(self.filters)]\n",
    "        fi_filter_values = filter_values[len(self.filters):]\n",
    "        assert len(fi_filter_values) == len(self.face_image_filters)\n",
    "        query = session.query(FaceImage, Image.identity, Image.image_id)\n",
    "        join_query = query \\\n",
    "            .join(CroppedImage, CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "            .join(Image, Image.image_id == CroppedImage.image_id) \\\n",
    "            .join(Detector) \\\n",
    "            .join(EmbeddingModel)\n",
    "        filter_query = join_query \\\n",
    "            .filter(EmbeddingModel.name == self.embeddingModel,\n",
    "                    Detector.name == self.detector) \\\n",
    "            .filter(Image.source.in_(self.calibration_db))\n",
    "        for cal_filter, value in zip(self.face_image_filters, fi_filter_values):\n",
    "            filter_query = filter_query.filter(FaceImage.__dict__[cal_filter] == value)\n",
    "        for cal_filter, value in zip(self.filters, im_filter_values):\n",
    "            filter_query = filter_query.filter(Image.__dict__[cal_filter] == value)\n",
    "        return filter_query.all()\n",
    "\n",
    "    def generate_lr_systems(self, calibration_pairs_per_category, test_pairs_per_category, session):\n",
    "\n",
    "        lr_systems = {}\n",
    "        for category, pairs in calibration_pairs_per_category.items():\n",
    "            y_cal = np.asarray([int(pair.same_identity) for pair in pairs]).flatten()\n",
    "\n",
    "            if self.embedding_model_as_scorer:\n",
    "                X_cal = pairs\n",
    "\n",
    "            else:\n",
    "\n",
    "                if self.embeddingModel == 'FaceVACs':\n",
    "                    cal_similarities = [pair.similarity for pair in pairs]\n",
    "                    X_cal = np.reshape(np.asarray(cal_similarities), (-1, 1))\n",
    "                else:\n",
    "                    # todo: check if normalizing is necessary.\n",
    "                    cal_distances = [pair.distance(self.metrics) for pair in pairs]\n",
    "                    X_cal = np.reshape(np.asarray(cal_distances), (-1, 1))\n",
    "\n",
    "            # Fit\n",
    "            if 0 < np.sum(y_cal) < len(pairs):\n",
    "                lr_systems[category] = CalibratedScorer(self.scorer, self.calibrator)\n",
    "                if self.embedding_model_as_scorer:\n",
    "                    lr_systems[category].fit_calibrator(X_cal, y_cal)\n",
    "                else:\n",
    "                    lr_systems[category].fit(X_cal, y_cal)\n",
    "\n",
    "            else:\n",
    "                del test_pairs_per_category[category]\n",
    "\n",
    "        if len(lr_systems.keys()) == 0:\n",
    "            return None\n",
    "\n",
    "        return lr_systems, test_pairs_per_category\n",
    "\n",
    "    def predict_lr(self, lr_systems, test_pairs_per_category, session):\n",
    "        results = defaultdict(list)\n",
    "        lrs_predicted = {}\n",
    "        for category, row_test_pairs in test_pairs_per_category.items():\n",
    "            # todo: converting pairs to facepairs. not the best place to do this.\n",
    "            # pairs = [test_pair.make_face_image_pair(session, self.detector, self.embeddingModel) for test_pair in\n",
    "            #         test_pairs]\n",
    "            pairs = [FacePair(row_test_pair[1], row_test_pair[2], row_test_pair[0].same_identity) for row_test_pair in\n",
    "                     row_test_pairs]\n",
    "            test_pairs = [row_test_pair[0] for row_test_pair in row_test_pairs]\n",
    "\n",
    "            test_norm_distances = [pair.norm_distance for pair in pairs]\n",
    "\n",
    "            if self.embedding_model_as_scorer:\n",
    "                X_test = pairs\n",
    "            else:\n",
    "                if self.embeddingModel == 'FaceVACs':\n",
    "                    test_similarities = [pair.similarity for pair in pairs]\n",
    "                    X_test = np.reshape(np.asarray(test_similarities), (-1, 1))\n",
    "                else:\n",
    "                    test_distances = [pair.distance(self.metrics) for pair in pairs]\n",
    "                    X_test = np.reshape(np.asarray(test_distances), (-1, 1))\n",
    "\n",
    "            lrs_predicted[category] = lr_systems[category].predict_lr(X_test)\n",
    "            y_test = [int(pair.same_identity) for pair in pairs]\n",
    "            results[\"test_pairs\"] += test_pairs\n",
    "            results[\"lrs_predicted\"] += list(lrs_predicted[category])\n",
    "            results[\"y_test\"] += y_test\n",
    "            results[\"test_norm_distances\"] += test_norm_distances\n",
    "\n",
    "        results['original_test_pairs'] = self.get_test_pairs(session)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def get_test_face_pairs(self, test_pairs, session):\n",
    "        pass\n",
    "\n",
    "    def create_output_dir(self):\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Converts the configuration of this experiment to a string that can be\n",
    "        used to generate file names for example.\n",
    "        \"\"\"\n",
    "        data_values = []\n",
    "        for k, v in self.data_config.items():\n",
    "            if k == 'datasets' and isinstance(v, tuple):\n",
    "                data_values.append('|'.join(map(str, v)))\n",
    "            else:\n",
    "                data_values.append(str(v))\n",
    "\n",
    "        params_str = '_'.join(map(str, self.params.values()))\n",
    "        return '_'.join(map(str, [\n",
    "            self.scorer,\n",
    "            self.calibrator,\n",
    "            params_str\n",
    "        ])).replace(':', '-')  # Windows forbids ':'\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lr-video",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "c08d8fec19e509e399d6ec1cb9b529f9385c45181b63bf2f2d9547e2a9a7b9b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

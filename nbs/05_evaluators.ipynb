{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluators\n",
    "\n",
    "> Class to evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti \n",
    "\n",
    "from typing import List, Iterator, Dict, Union, Tuple, Optional\n",
    "\n",
    "from lr_video_face.experiments import Experiment, ExperimentalSetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class ExperimentEvaluator:\n",
    "    def __init__(self, \n",
    "    experiment: Experiment,\n",
    "    cllr_expert_per_year: Dict[int, list],\n",
    "    results: Dict[str, list],\n",
    "    save_plots: bool = True\n",
    "    ):\n",
    "\n",
    "        self.experiment = experiment\n",
    "        self.cllr_expert_per_year = cllr_expert_per_year\n",
    "        self.results = results\n",
    "        self.save_plots = save_plots\n",
    "        self.experiment_directory = self.experiment.output_dir\n",
    "        self.cllr_auto_per_year = self.get_cllr_auto_per_year()\n",
    "    \n",
    "\n",
    "    def make_plots(self):\n",
    "        # self.plot_cllr_quality_2015()\n",
    "        # self.plot_cllr_quality_2015_v2()\n",
    "        # self.plot_lr_distributions()\n",
    "        # self.plot_ROC_curve()\n",
    "        # self.plot_performance_as_function_of_yaw()\n",
    "        # self.plot_performance_as_function_of_categories()\n",
    "        # self.plot_tippett()\n",
    "        self.plot_ece()\n",
    "        self.plot_cllr()\n",
    "        # todo: fix test plotting.\n",
    "        # self.test_plotting()\n",
    "\n",
    "    def plot_lr_distributions(self, show=None):\n",
    "        \"\"\"\n",
    "        Plots the 10log LRs generated for the two hypotheses by the fitted system.\n",
    "        \"\"\"\n",
    "        predicted_log_lrs = np.log10(self.results[\"lrs_predicted\"])\n",
    "        plt.figure(figsize=(10, 10), dpi=100)\n",
    "        points0, points1 = Xy_to_Xn(predicted_log_lrs, np.array(self.results['y_test']))\n",
    "        plt.hist(points0, bins=20, alpha=.25, density=True)\n",
    "        plt.hist(points1, bins=20, alpha=.25, density=True)\n",
    "        plt.xlabel(r'$log_{10}$ LR')\n",
    "        if self.save_plots:\n",
    "            savefig = os.path.join(self.experiment_directory, \"lr_distributions\")\n",
    "            plt.savefig(savefig, dpi=600)\n",
    "            plt.close()\n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "    def plot_cllr_quality_2015(self, show=None):\n",
    "        \"\"\"\n",
    "        Plots cllr obtained as function of Terhorst quality\n",
    "        \"\"\"\n",
    "\n",
    "        y = self.results['y_test']\n",
    "        lr = self.results['lrs_predicted']\n",
    "        quality_pair = [(x.first.terhorst_quality_rounded, x.second.terhorst_quality_rounded) for x in\n",
    "                        self.results['test_pairs']]\n",
    "        quality = [x.quality for x in self.results['test_pairs']]\n",
    "        comparisons = [str(test_pair.comparison) for test_pair in self.results['test_pairs']]\n",
    "\n",
    "        data_per_comparison = defaultdict(list)\n",
    "        data = zip(y, lr, quality, quality_pair)\n",
    "        for datum, comparison in zip(data, comparisons):\n",
    "            if datum[2] != -1:\n",
    "                data_per_comparison[comparison].append(datum)\n",
    "\n",
    "        for comparison, datum in data_per_comparison.items():\n",
    "            data_per_comparison[comparison] = sorted(datum, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "        n_points = 10\n",
    "        data_per_point = defaultdict(list)\n",
    "        for point in range(n_points):\n",
    "            for comparison, datum in list(data_per_comparison.items()):\n",
    "                if datum:\n",
    "                    quality_1 = datum[0][2]\n",
    "                    data_per_point[point] += [d_cllr for d_cllr in datum if d_cllr[2] == quality_1]\n",
    "                    data_per_comparison[comparison] = [d_cllr for d_cllr in datum if d_cllr[2] < quality_1]\n",
    "\n",
    "        cllrs = []\n",
    "        cllrs_acum = []\n",
    "        quality_label = []\n",
    "        lr_p_a = []\n",
    "        y_p_a = []\n",
    "        df_quality = pd.DataFrame(\n",
    "            columns=['Ref Min Quality', 'Frame Min Quality', 'Cllr Value', 'Cllr Type', 'Number of Pairs',\n",
    "                     'Quality Rank'])\n",
    "        for point, datum in data_per_point.items():\n",
    "            y_p = [data[0] for data in datum]\n",
    "            lr_p = [data[1] for data in datum]\n",
    "            y_p_a += y_p\n",
    "            lr_p_a += lr_p\n",
    "            min_quality = min([data[2] for data in datum])\n",
    "            quality_label.append(min_quality)\n",
    "            cllr = lir.metrics.cllr(np.asarray(lr_p), np.asarray(y_p))\n",
    "            cllr_acum = lir.metrics.cllr(np.asarray(lr_p_a), np.asarray(y_p_a))\n",
    "\n",
    "            cllrs.append(cllr)\n",
    "            cllrs_acum.append(cllr_acum)\n",
    "            print(f' point: {point}')\n",
    "            print(f' cllr: {cllr}')\n",
    "            print(f' cllr acum: {cllr_acum}')\n",
    "            print(f' quality label: {min_quality}')\n",
    "\n",
    "            df_quality = df_quality.append({'Ref Min Quality': min([data[3][1] for data in datum]),\n",
    "                                            'Frame Min Quality': min([data[3][0] for data in datum]),\n",
    "                                            'Cllr Value': cllr,\n",
    "                                            'Cllr Type': 'Not accumulated',\n",
    "                                            'Number of Pairs': len(y_p),\n",
    "                                            'Quality Rank': point + 1},\n",
    "                                           ignore_index=True)\n",
    "            df_quality = df_quality.append({'Ref Min Quality': min([data[3][1] for data in datum]),\n",
    "                                            'Frame Min Quality': min([data[3][0] for data in datum]),\n",
    "                                            'Cllr Value': cllr_acum,\n",
    "                                            'Cllr Type': 'Accumulated',\n",
    "                                            'Number of Pairs': len(y_p_a),\n",
    "                                            'Quality Rank': point + 1},\n",
    "                                           ignore_index=True)\n",
    "\n",
    "        # import dill  # pip install dill --user\n",
    "        filename = 'globalsave.pkl'\n",
    "        dill.dump_session(filename)\n",
    "\n",
    "        plt.scatter(range(n_points), cllrs, label='cllr', marker='o')\n",
    "        plt.scatter(range(n_points), cllrs_acum, label='cllr accumulated', marker='*')\n",
    "        cllr_labels = ['cllr', 'cllr_accumulated']\n",
    "        plt.legend(labels=cllr_labels)\n",
    "        plt.xticks(range(n_points), quality_label)\n",
    "        plt.xlabel('SER-FIQ quality')\n",
    "        plt.ylabel('Cllr')\n",
    "        plt.title('Cllr by quality for year 2015')\n",
    "\n",
    "        if self.save_plots:\n",
    "            savefig = os.path.join(self.experiment_directory, \"cllr_quality_by_pairs\")\n",
    "            plt.savefig(savefig, dpi=600)\n",
    "            plt.close()\n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "        markers = {\"Accumulated\": \"s\", \"Not accumulated\": \"X\"}\n",
    "        sns.scatterplot(data=df_quality, x='Frame Min Quality', y='Ref Min Quality', hue='Cllr Value',\n",
    "                        size='Number of Pairs', style='Cllr Type', markers=markers)\n",
    "\n",
    "        if self.save_plots:\n",
    "            savefig = os.path.join(self.experiment_directory, \"cllr_quality_by_pairs_2\")\n",
    "            plt.savefig(savefig, dpi=600)\n",
    "            plt.close()\n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "    def plot_cllr_quality_2015_v2(self, show=None):\n",
    "        \"\"\"\n",
    "        Plots cllr obtained as function of Terhorst quality\n",
    "        \"\"\"\n",
    "\n",
    "        y = self.results['y_test']\n",
    "        lr = self.results['lrs_predicted']\n",
    "        quality = [x.quality for x in self.results['test_pairs']]\n",
    "\n",
    "        data = sorted(zip(quality, lr, y), key=lambda x: x[0])\n",
    "\n",
    "        quality = [a for a, _, _ in data if a != -1]\n",
    "        lr = [b for a, b, _ in data if a != -1]\n",
    "        y = [c for a, _, c in data if a != -1]\n",
    "\n",
    "        st = 0\n",
    "        cllr = []\n",
    "\n",
    "        counts, bins, bars = plt.hist(quality, bins=6)\n",
    "        limits = itertools.accumulate(counts)\n",
    "        for limit in limits:\n",
    "            limit = int(limit)\n",
    "            lrp = lr[st:limit]\n",
    "            yp = y[st:limit]\n",
    "            cllr.append(lir.metrics.cllr(np.asarray(lrp),\n",
    "                                         np.asarray(yp)))\n",
    "            # print(cllr)\n",
    "            st = limit\n",
    "\n",
    "        plt.figure(figsize=(10, 10), dpi=100)\n",
    "        plt.scatter(bins[1:], cllr)\n",
    "        plt.xlabel('SER-FIQ Quality')\n",
    "        plt.ylabel('Cllr')\n",
    "        plt.title('Cllr by quality bins for year 2015')\n",
    "        if self.save_plots:\n",
    "            savefig = os.path.join(self.experiment_directory, \"cllr_quality\")\n",
    "            plt.savefig(savefig, dpi=600)\n",
    "            plt.close()\n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "    def plot_ROC_curve(self,\n",
    "                       show: Optional[bool] = False):\n",
    "        norm_distances = np.asarray(self.results[\"test_norm_distances\"])\n",
    "        fpr, tpr, thresholds = roc_curve(self.results['y_test'], 1 - norm_distances)\n",
    "        plt.figure(figsize=(10, 10), dpi=100)\n",
    "        plt.plot(fpr, fpr, linestyle='--', label='No Skill')\n",
    "        plt.plot(fpr, tpr, color='r', label=r'ROC curve')\n",
    "        plt.xlabel('False positive rate (1 - specificity)')\n",
    "        plt.ylabel('True positive rate (sensitivity)')\n",
    "        plt.title('ROC curve')\n",
    "        plt.legend()\n",
    "        if self.save_plots:\n",
    "            savefig = os.path.join(self.experiment_directory, \"ROC_curve\")\n",
    "            plt.savefig(savefig, dpi=600)\n",
    "            plt.close()\n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "    def plot_performance_as_function_of_yaw(self,\n",
    "                                            show: Optional[bool] = None):\n",
    "        \"\"\"\n",
    "        plots the scores as a function of the maximum yaw (=looking sideways) on\n",
    "        the images, coloured by ground truth. calls plt.show() if show is True.\n",
    "        \"\"\"\n",
    "        df_yaws = pd.DataFrame(columns=['pair_id', 'y_test', 'yaw_first', 'yaw_second', 'score'])\n",
    "        for i, test_pair in enumerate(self.results['test_pairs']):\n",
    "            df_yaws = df_yaws.append(dict(pair_id=i,\n",
    "                                          y_test=self.results['y_test'][i],\n",
    "                                          yaw_first=test_pair.first.yaw.value,\n",
    "                                          yaw_second=test_pair.second.yaw.value,\n",
    "                                          score=self.results[\"test_norm_distances\"][i]),\n",
    "                                     ignore_index=True)\n",
    "\n",
    "        sns.catplot(x=\"yaw_second\", y=\"score\", row='yaw_first', hue='y_test', kind=\"swarm\", data=df_yaws)\n",
    "        plt.grid()\n",
    "        if self.save_plots:\n",
    "            savefig = os.path.join(self.experiment_directory, \"performance_as_function_of_yaw\")\n",
    "            plt.savefig(savefig, dpi=600)\n",
    "            plt.close()\n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "    def plot_performance_as_function_of_categories(self,\n",
    "                                                   show: Optional[bool] = None):\n",
    "        \"\"\"\n",
    "        plots the scores as a function of the maximum yaw (=looking sideways) on\n",
    "        the images, coloured by ground truth. calls plt.show() if show is True.\n",
    "        \"\"\"\n",
    "        categories = self.experiment.filters\n",
    "        first = lambda c: 'first_' + c\n",
    "        second = lambda c: 'second_' + c\n",
    "        first_categories = list(map(first, categories))\n",
    "        second_categories = list(map(second, categories))\n",
    "        df_categories = pd.DataFrame(columns=first_categories + second_categories + ['y_test'] + ['scores'])\n",
    "        df_categories['y_test'] = self.results['y_test']\n",
    "        df_categories['scores'] = self.results['test_norm_distances']\n",
    "        for i, category in enumerate(categories):\n",
    "            df_categories[first_categories[i]] = [pair.first.__dict__[category] for pair in self.results['test_pairs']]\n",
    "            df_categories[second_categories[i]] = [pair.second.__dict__[category] for pair in\n",
    "                                                   self.results['test_pairs']]\n",
    "\n",
    "        sns.pairplot(df_categories)\n",
    "        print(\"hola\")\n",
    "\n",
    "        for i, test_pair in enumerate(self.results['test_pairs']):\n",
    "            df_yaws = df_yaws.append(dict(pair_id=i,\n",
    "                                          y_test=self.results['y_test'][i],\n",
    "                                          yaw_first=test_pair.first.yaw.value,\n",
    "                                          yaw_second=test_pair.second.yaw.value,\n",
    "                                          score=self.results[\"test_norm_distances\"][i]),\n",
    "                                     ignore_index=True)\n",
    "\n",
    "        sns.catplot(x=\"yaw_second\", y=\"score\", row='yaw_first', hue='y_test', kind=\"swarm\", data=df_yaws)\n",
    "        plt.grid()\n",
    "        if self.save_plots:\n",
    "            savefig = os.path.join(self.experiment_directory, \"performance_as_function_of_yaw\")\n",
    "            plt.savefig(savefig, dpi=600)\n",
    "            plt.close()\n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "    # todo: add resolution to image attributes.\n",
    "    # todo: fix the second plot.\n",
    "    '''        \n",
    "\n",
    "    def plot_performance_as_function_of_resolution(scores,\n",
    "                                                   test_pairs: List[FacePair],\n",
    "                                                   y_test,\n",
    "                                                   show_ratio: bool = False,\n",
    "                                                   savefig: Optional[str] = None,\n",
    "                                                   show: Optional[bool] = None):\n",
    "        \"\"\"\n",
    "        plots the scores as a function of the minimum resolution found on the\n",
    "        two images of the pair, coloured by ground truth\n",
    "        \"\"\"\n",
    "\n",
    "        if show_ratio:\n",
    "            resolutions = [np.prod(pair.first.get_image().shape[:2]) /\n",
    "                           np.prod(pair.second.get_image().shape[:2]) for\n",
    "                           pair in test_pairs]\n",
    "            label = 'ratio pixels'\n",
    "        else:\n",
    "            resolutions = [min(np.prod(pair.first.get_image().shape[:2]),\n",
    "                               np.prod(\n",
    "                                   pair.second.get_image().shape[:2])) / 10 ** 6\n",
    "                           for pair in test_pairs]\n",
    "            label = 'Mpixels (smallest image)'\n",
    "\n",
    "        plot_performance_as_a_function_of_x(\n",
    "            properties=resolutions,\n",
    "            scores=scores,\n",
    "            y_test=y_test,\n",
    "            x_label=label,\n",
    "            savefig=savefig,\n",
    "            show=show)\n",
    "            \n",
    "    \n",
    "\n",
    "    def plot_performance_as_a_function_of_x(\n",
    "            properties: List[float],\n",
    "            scores: List[float],\n",
    "            y_test: List[Union[int, bool]],\n",
    "            x_label: str, savefig: Optional[str], show: bool,\n",
    "            bins: Optional[List[Tuple[float, float]]] = None):\n",
    "        \"\"\"\n",
    "        plots the scores as a function of some vector of properties, coloured by\n",
    "        ground truth. Includes mean in each of the bins, if provided\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 10), dpi=100)\n",
    "        colors = list(map(lambda x: 'blue' if x else 'red', y_test))\n",
    "        plt.scatter(properties, scores, c=colors)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel('score')\n",
    "        if bins:\n",
    "            for bin in bins:\n",
    "                avg = np.mean([score for score, prop, y in\n",
    "                               zip(scores, properties, y_test)\n",
    "                               if bin[0] < prop < bin[1] and y])\n",
    "                plt.plot(bin, [avg, avg], c='blue')\n",
    "                avg = np.mean([score for score, prop, y in\n",
    "                               zip(scores, properties, y_test)\n",
    "                               if bin[0] < prop < bin[1] and not y])\n",
    "                plt.plot(bin, [avg, avg], c='red')\n",
    "        if savefig is not None:\n",
    "            plt.savefig(savefig)\n",
    "            plt.close()\n",
    "        if show or savefig is None:\n",
    "            plt.show()\n",
    "            \n",
    "        '''\n",
    "\n",
    "    def plot_tippett(self, show=None):\n",
    "        # predicted_log_lrs, y, savefig=None, show=None):\n",
    "        \"\"\"\n",
    "        Plots the 10log LRs in a Tippett plot.\n",
    "        \"\"\"\n",
    "\n",
    "        predicted_log_lrs = np.log10(self.results[\"lrs_predicted\"])\n",
    "        xplot = np.linspace(\n",
    "            start=np.min(predicted_log_lrs),\n",
    "            stop=np.max(predicted_log_lrs),\n",
    "            num=100\n",
    "        )\n",
    "        lr_0, lr_1 = Xy_to_Xn(predicted_log_lrs, np.array(self.results[\"y_test\"]))\n",
    "        perc0 = (sum(i > xplot for i in lr_0) / len(lr_0)) * 100\n",
    "        perc1 = (sum(i > xplot for i in lr_1) / len(lr_1)) * 100\n",
    "\n",
    "        plt.figure(figsize=(10, 10), dpi=100)\n",
    "        plt.plot(xplot, perc1, color='b', label=r'LRs given $\\mathregular{H_1}$')\n",
    "        plt.plot(xplot, perc0, color='r', label=r'LRs given $\\mathregular{H_2}$')\n",
    "        plt.axvline(x=0, color='k', linestyle='--')\n",
    "        plt.xlabel('Log likelihood ratio')\n",
    "        plt.ylabel('Cumulative proportion')\n",
    "        plt.title('Tippett plot')\n",
    "        plt.legend()\n",
    "        if self.save_plots:\n",
    "            savefig = os.path.join(self.experiment_directory, \"tippet_plot\")\n",
    "            plt.savefig(savefig, dpi=600)\n",
    "            plt.close()\n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "    def test_plotting(self, show=None):\n",
    "        with lir.plotting.show() as ax:\n",
    "            ax.pav(np.asarray(self.results[\"lrs_predicted\"]), np.asarray(self.results[\"y_test\"]))\n",
    "\n",
    "        if self.save_plots:\n",
    "            savefig = os.path.join(self.experiment_directory, \"test_plot\")\n",
    "            ax.savefig(savefig)\n",
    "            ax.close()\n",
    "        if show:\n",
    "            ax.show()\n",
    "\n",
    "    def plot_ece(self) -> object:\n",
    "        savefig = os.path.join(self.experiment_directory, \"ECE_plot\")\n",
    "        plot(np.asarray(self.results[\"lrs_predicted\"]), np.asarray(self.results[\"y_test\"]), path=savefig,\n",
    "             kw_figure={'figsize': (10, 10), 'dpi': 100})\n",
    "\n",
    "    def plot_cllr(self, show=None):\n",
    "        \"\"\"\n",
    "        Plots cllr value for ENFSI tests. It computes both cllr of automated systems with the cllrs from experts.\n",
    "        If there is no ENFSI data, this graph does not show.\n",
    "\n",
    "        # todo: save table with cllr results.\n",
    "        \"\"\"\n",
    "\n",
    "        cllr_auto_df = pd.DataFrame(columns=['Year', 'Expert', 'Cllr'])\n",
    "        cllr_exp_df = pd.DataFrame(columns=['Year', 'Expert', 'Cllr'])\n",
    "        years = self.experiment.enfsi_years\n",
    "\n",
    "        for year in years:\n",
    "            for cllr_exp in self.cllr_expert_per_year[year]:\n",
    "                cllr_exp_df = cllr_exp_df.append({'Year': str(year), 'LR Estimator': \"Participant\", 'Cllr': cllr_exp},\n",
    "                                                 ignore_index=True)\n",
    "\n",
    "            cllr_auto = self.cllr_auto_per_year[year]\n",
    "            cllr_auto_df = cllr_auto_df.append(\n",
    "                {'Year': str(year), 'LR Estimator': self.experiment.embeddingModel, 'Cllr': cllr_auto},\n",
    "                ignore_index=True)\n",
    "\n",
    "        cllr_df = cllr_exp_df.append(cllr_auto_df)\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sc_plot = sns.catplot(data=cllr_df, x=\"Year\", y=\"Cllr\", hue=\"LR Estimator\",\n",
    "                              palette=sns.color_palette(['orange', 'blue']))\n",
    "        # sc_plot.set_title(\"Cllrs for Automated system and ENFSI participants\")\n",
    "        # sc_plot.set(xticks=[map(str, years)])\n",
    "\n",
    "        if self.save_plots:\n",
    "            savefig = os.path.join(self.experiment_directory, \"cllr_experts\")\n",
    "            plt.savefig(savefig, dpi=600)\n",
    "            plt.close()\n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "    \n",
    "    def get_cllr_auto_per_year(self):\n",
    "        years = [pair.first.year for pair in self.results[\"test_pairs\"]]\n",
    "        lrs_predicted = self.results[\"lrs_predicted\"]\n",
    "        y_test = self.results[\"y_test\"]\n",
    "\n",
    "        data_per_year = zip(years, lrs_predicted, y_test)\n",
    "\n",
    "        lrs_predicted_per_year = defaultdict(list)\n",
    "        y_test_per_year = defaultdict(list)\n",
    "\n",
    "        for year, lr, y in data_per_year:\n",
    "            lrs_predicted_per_year[year].append(lr)\n",
    "            y_test_per_year[year].append(y)\n",
    "\n",
    "        cllr_auto_per_year = {}\n",
    "\n",
    "        for year in np.unique(years):\n",
    "            cllr_auto_per_year[year] = lir.metrics.cllr(np.asarray(lrs_predicted_per_year[year]),\n",
    "                                                        np.asarray(y_test_per_year[year]))\n",
    "\n",
    "        return cllr_auto_per_year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class GlobalEvaluator:\n",
    "\n",
    "    def __init__(self, \n",
    "    experiments: ExperimentalSetup,\n",
    "    save_plots: bool = True\n",
    "    ):\n",
    "\n",
    "        self.experiments = experiments\n",
    "        self.save_plots = save_plots\n",
    "        self.experiment_evaluators = self.get_experiment_evaluators(self.experiments)    \n",
    "\n",
    "\n",
    "\n",
    "    def make_global_plot(self):\n",
    "        experiment_df = pd.DataFrame(\n",
    "            columns=['Year', 'Filters', 'Detector', 'Embedding Model', 'Calibrator', 'Cllr'])\n",
    "        filters = self.experiments.filters + self.experiments.face_image_filters\n",
    "        str_filters = \",\".join(filters)\n",
    "        for evaluator in self.experiment_evaluators:\n",
    "\n",
    "            if isinstance(evaluator.experiment.calibrator, IsotonicCalibrator):\n",
    "                calibrator_name = 'Isotonic Calibrator'\n",
    "            else:\n",
    "                calibrator_name = str(evaluator.experiment.calibrator)\n",
    "\n",
    "            for year in evaluator.experiment.enfsi_years:\n",
    "                experiment_df = experiment_df.append(\n",
    "                    {'Year': year, 'Filters': str_filters, 'Detector': evaluator.experiment.detector,\n",
    "                     'Embedding Model': evaluator.experiment.embeddingModel,\n",
    "                     'Calibrator': calibrator_name.split(\"(\")[0],\n",
    "                     'Cllr': evaluator.cllr_auto_per_year[year],\n",
    "                     }, ignore_index=True)\n",
    "\n",
    "        for year in self.experiments.enfsi_years:\n",
    "            for detector in self.experiments.detectors:\n",
    "                for calibrator in self.experiments.calibrators:\n",
    "\n",
    "                    if isinstance(calibrator, IsotonicCalibrator):\n",
    "                        calibrator_name = 'Isotonic Calibrator'\n",
    "                    else:\n",
    "                        calibrator_name = str(calibrator)\n",
    "\n",
    "                    experiment_df = experiment_df.append(\n",
    "                        {'Year': year, 'Filters': str_filters, 'Detector': detector,\n",
    "                         'Embedding Model': \"Average Participants\",\n",
    "                         'Calibrator': calibrator_name.split(\"(\")[0],\n",
    "                         'Cllr': mean(self.experiments.cllr_expert_per_year[year])\n",
    "                         }, ignore_index=True)\n",
    "\n",
    "        experiment_df.to_excel(os.path.join(self.experiments.output_dir,\n",
    "                                             f'results_file_ES{self.experiments.embedding_model_as_scorer}.xlsx'))\n",
    "\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.catplot(data=experiment_df, x=\"Year\", y=\"Cllr\", hue=\"Embedding Model\", row=\"Calibrator\", col=\"Detector\")\n",
    "        savefig = os.path.join(self.experiments.output_dir,\n",
    "                               f\"cllr_summary_ES{self.experiments.embedding_model_as_scorer}\")\n",
    "        plt.savefig(savefig)\n",
    "        plt.close()\n",
    "\n",
    "    def make_experiment_plots(self):\n",
    "        for evaluator in self.experiment_evaluators:\n",
    "            evaluator.make_plots()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_experiment_evaluators(experiments: ExperimentalSetup) -> List[ExperimentEvaluator]:\n",
    "        evaluators = []\n",
    "        for experiment in tqdm(experiments):\n",
    "            results = experiment.perform()\n",
    "            evaluation = ExperimentEvaluator(experiment=experiment, results=results, cllr_expert_per_year=experiments.cllr_expert_per_year)\n",
    "            evaluators.append(evaluation)\n",
    "        return evaluators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lr-video",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

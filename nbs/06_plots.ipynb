{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plots\n",
    "\n",
    "> Plot generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "\n",
    "from typing import Dict, List, Optional\n",
    "from sklearn.metrics import roc_curve\n",
    "from lir import Xy_to_Xn, metrics\n",
    "from lir.ece import plot \n",
    "\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensi All years\n",
    "image-to-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def plot_lr_distributions(results:Dict, experiment_directory, save_plots:bool = True, show: Optional[bool] = False):\n",
    "    \"\"\"\n",
    "    Plots the 10log LRs generated for the two hypotheses by the fitted system.\n",
    "    \"\"\"\n",
    "    predicted_log_lrs = np.log10(results[\"lrs_predicted\"])\n",
    "    plt.figure(figsize=(10, 10), dpi=100)\n",
    "    points0, points1 = Xy_to_Xn(predicted_log_lrs, np.array(results['y_test']))\n",
    "    plt.hist(points0, bins=20, alpha=.25, density=True)\n",
    "    plt.hist(points1, bins=20, alpha=.25, density=True)\n",
    "    plt.xticks(fontsize = 22)\n",
    "    plt.yticks(fontsize = 22)\n",
    "    plt.xlabel(r'$log_{10}$ LR',size = 24)\n",
    "    plt.ylabel('Density',size = 24)\n",
    "    \n",
    "    if save_plots:\n",
    "        savefig = os.path.join(experiment_directory, \"lr_distributions3\")\n",
    "        plt.savefig(savefig, dpi=600)\n",
    "        plt.close()\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def plot_ROC_curve(results:Dict, experiment_directory, save_plots:bool = True, show: Optional[bool] = False):\n",
    "\n",
    "    norm_distances = np.asarray(results[\"test_norm_distances\"])\n",
    "    fpr, tpr, thresholds = roc_curve(results['y_test'], 1 - norm_distances)\n",
    "    plt.figure(figsize=(10, 10), dpi=100)\n",
    "    plt.plot(fpr, fpr, linestyle='--', label='No Skill')\n",
    "    plt.plot(fpr, tpr, color='r', label=r'ROC curve')\n",
    "    plt.xlabel('False positive rate (1 - specificity)')\n",
    "    plt.ylabel('True positive rate (sensitivity)')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend()\n",
    "    if save_plots:\n",
    "        savefig = os.path.join(experiment_directory, \"ROC_curve\")\n",
    "        plt.savefig(savefig, dpi=600)\n",
    "        plt.close()\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def plot_tippett(results:Dict, experiment_directory, save_plots:bool = True, show: Optional[bool] = False):\n",
    "        \n",
    "    \"\"\"\n",
    "    Plots the 10log LRs in a Tippett plot.\n",
    "    \"\"\"\n",
    "\n",
    "    predicted_log_lrs = np.log10(results[\"lrs_predicted\"])\n",
    "\n",
    "    xplot = np.linspace(\n",
    "        start=np.min(predicted_log_lrs),\n",
    "        stop=np.max(predicted_log_lrs),\n",
    "        num=100\n",
    "    )\n",
    "\n",
    "    lr_0, lr_1 = Xy_to_Xn(predicted_log_lrs, np.array(results[\"y_test\"]))\n",
    "\n",
    "    perc0 = (sum(i > xplot for i in lr_0) / len(lr_0)) * 100\n",
    "    perc1 = (sum(i > xplot for i in lr_1) / len(lr_1)) * 100\n",
    "\n",
    "    plt.figure(figsize=(10, 10), dpi=600)\n",
    "    plt.plot(xplot, perc1, color='b', label=r'LRs given $\\mathregular{H_1}$')\n",
    "    plt.plot(xplot, perc0, color='r', label=r'LRs given $\\mathregular{H_2}$')\n",
    "    plt.axvline(x=0, color='k', linestyle='--')\n",
    "    plt.xlabel('Log likelihood ratio')\n",
    "    plt.ylabel('Cumulative proportion')\n",
    "    plt.title('Tippett plot')\n",
    "    plt.legend()\n",
    "\n",
    "    if save_plots:\n",
    "        savefig = os.path.join(experiment_directory, \"tippet_plot\")\n",
    "        plt.savefig(savefig, dpi=600)\n",
    "        plt.close()\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def plot_cllr(results:Dict, experiment_directory, enfsi_years: List[int], cllr_expert_per_year:Dict, \n",
    "    cllr_auto_per_year:Dict, embeddingModel, save_plots:bool = True, show: Optional[bool] = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Plots cllr value for ENFSI tests. It computes both cllr of automated systems with the cllrs from experts.\n",
    "    If there is no ENFSI data, this graph does not show.\n",
    "\n",
    "    # todo: save table with cllr results.\n",
    "    \"\"\"\n",
    "\n",
    "    cllr_auto_df = pd.DataFrame(columns=['Year', 'Expert', 'Cllr'])\n",
    "    cllr_exp_df = pd.DataFrame(columns=['Year', 'Expert', 'Cllr'])\n",
    "    years = enfsi_years\n",
    "\n",
    "    for year in years:\n",
    "        for cllr_exp in cllr_expert_per_year[year]:\n",
    "            cllr_exp_df = cllr_exp_df.append({'Year': str(year), 'LR Estimator': \"Participant\", 'Cllr': cllr_exp},\n",
    "                                                ignore_index=True)\n",
    "\n",
    "        cllr_auto = cllr_auto_per_year[year]\n",
    "        cllr_auto_df = cllr_auto_df.append(\n",
    "            {'Year': str(year), 'LR Estimator': embeddingModel, 'Cllr': cllr_auto},\n",
    "            ignore_index=True)\n",
    "\n",
    "\n",
    "    cllr_df = cllr_exp_df.append(cllr_auto_df)\n",
    "    #Cada LR estimator va en un color\n",
    "    paleta = ['orange', 'blue']\n",
    "\n",
    "    # añadimos el cllr de las imagen promediadas\n",
    "    if len(results['lrs_predicted_2015']):\n",
    "        x = metrics.cllr(np.asarray(results['lrs_predicted_2015']), np.asarray(results['y_test_2015']))    \n",
    "        cllr_df = cllr_df.append({'Year': str(2015), 'LR Estimator': 'Quality weighted Images', 'Cllr': x},\n",
    "            ignore_index=True)\n",
    "        paleta.append('red')\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sc_plot = sns.catplot(data=cllr_df, x=\"Year\", y=\"Cllr\", hue=\"LR Estimator\",\n",
    "                            palette=sns.color_palette(paleta))\n",
    "\n",
    "    # sc_plot.set_title(\"Cllrs for Automated system and ENFSI participants\")\n",
    "    # sc_plot.set(xticks=[map(str, years)])\n",
    "\n",
    "    if save_plots:\n",
    "        savefig = os.path.join(experiment_directory, \"cllr_experts\")\n",
    "        plt.savefig(savefig, dpi=600)\n",
    "        plt.close()\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def plot_ece(results:Dict, experiment_directory, save_plots:bool = True) -> object:\n",
    "        savefig = os.path.join(experiment_directory, \"ECE_plot\")\n",
    "        plot(np.asarray(results[\"lrs_predicted\"]), np.asarray(results[\"y_test\"]), path=savefig, kw_figure={'figsize': (10, 10), 'dpi': 600})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfsi 2015\n",
    "image-to-video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def plot_cllr_per_qualitydrop(cllrs_2015:Dict[float,float], cllr_expert_per_year,\n",
    "experiment_directory,\n",
    "save_plots:bool = True, \n",
    "show: Optional[bool] = False):\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(cllrs_2015, orient='index', columns=['Cllr'])    \n",
    "    df = df.reset_index(drop = False)\n",
    "    df.rename(columns={'index': 'Quality Drop'}, inplace=True)\n",
    "    \n",
    "    df['legend'] = 'Automatic System'\n",
    "    \n",
    "    #df.reset_index(inplace = True)\n",
    "    # cllr es un valor promedio del error cometido en las observaciones. \n",
    "    # como cada observador tiene el mismo número de observaciones, \n",
    "    # el promedio global es igual al promedio de los valores obtenidos por cada observador.\n",
    "    cllr_experts = np.mean(cllr_expert_per_year[2015])\n",
    "\n",
    "    #para dibujar en la gráfica\n",
    "    x1 = np.min(df['Quality Drop'])\n",
    "    x2 = np.max(df['Quality Drop'])    \n",
    "\n",
    "    df = df.append({'Quality Drop': x1, 'Cllr': cllr_experts, 'legend': 'Participants'}, ignore_index = True)\n",
    "    df = df.append({'Quality Drop': x2, 'Cllr': cllr_experts, 'legend': 'Participants'}, ignore_index = True)\n",
    "\n",
    "    #hay que ordenar os datos para que no aparezcan leyendas múltiples\n",
    "    df.sort_values(by= ['legend', 'Quality Drop'], inplace = True)\n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sc_plot = sns.lineplot(data=df, x='Quality Drop', y=\"Cllr\", hue = 'legend', marker='s')\n",
    "    sc_plot.set(xscale=\"log\")\n",
    "\n",
    "    sc_plot.set_title(\"Cllrs for Automated system and ENFSI year 2015 according to quality drop\")\n",
    "    # sc_plot.set(xticks=[map(str, years)])\n",
    "\n",
    "    if save_plots:\n",
    "        savefig = os.path.join(experiment_directory, \"cllr_2015_quality_drop\")\n",
    "        plt.savefig(savefig, dpi=600)\n",
    "        plt.close()\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_cllr_per_common_attributes(results:Dict, cllr_expert_per_year,\n",
    "experiment_directory,\n",
    "save_plots:bool = True, \n",
    "show: Optional[bool] = False):\n",
    "\n",
    "    df0 = pd.DataFrame({'lr':results['lrs_predicted'],\\\n",
    "        'y': results['y_test'],\\\n",
    "        'common_attributes':results['common_attributes'],\\\n",
    "        'drop':results['quality_drops']})\n",
    "        \n",
    "    \n",
    "    df0 = df0.loc[(df0['drop']==1)]\n",
    "    df0 = df0.reset_index(drop = True)\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for n in np.unique(df0['common_attributes']):\n",
    "        dfn = df0.loc[(df0['common_attributes'] == n)]\n",
    "        x = metrics.cllr(np.asarray(dfn['lr']), np.asarray(dfn['y']))    \n",
    "        df = df.append({'legend': 'Automatic System', 'Common Attributes': n, 'Cllr': x}, ignore_index=True)    \n",
    "\n",
    "    df = df.reset_index(drop = False)\n",
    "    \n",
    "    \n",
    "    #df.reset_index(inplace = True)\n",
    "    # cllr es un valor promedio del error cometido en las observaciones. \n",
    "    # como cada observador tiene el mismo número de observaciones, \n",
    "    # el promedio global es igual al promedio de los valores obtenidos por cada observador.\n",
    "    cllr_experts = np.mean(cllr_expert_per_year[2015])\n",
    "\n",
    "    #para dibujar en la gráfica\n",
    "    x1 = np.min(df['Common Attributes'])\n",
    "    x2 = np.max(df['Common Attributes'])    \n",
    "\n",
    "    df = df.append({'legend': 'Participants', 'Common Attributes': x1, 'Cllr': cllr_experts}, ignore_index = True)\n",
    "    df = df.append({'legend': 'Participants', 'Common Attributes': x2, 'Cllr': cllr_experts}, ignore_index = True)\n",
    "\n",
    "    #hay que ordenar os datos para que no aparezcan leyendas múltiples\n",
    "    df.sort_values(by= ['legend', 'Common Attributes'], inplace = True)\n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sc_plot = sns.lineplot(data=df, x='Common Attributes', y=\"Cllr\", hue = 'legend', marker='s')\n",
    "    #sc_plot.set(xscale=\"log\")\n",
    "\n",
    "    sc_plot.set_title(\"Cllrs for Automated system and ENFSI year 2015 according to number of matching attributes\")\n",
    "    # sc_plot.set(xticks=[map(str, years)])\n",
    "\n",
    "    if save_plots:\n",
    "        savefig = os.path.join(experiment_directory, \"cllr_2015_common_atts\")\n",
    "        plt.savefig(savefig, dpi=600)\n",
    "        plt.close()\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def plot_new(results:Dict, cllr_expert_per_year,\n",
    "experiment_directory,\n",
    "save_plots:bool = True, \n",
    "show: Optional[bool] = False):    \n",
    "\n",
    "    # the results are only received for 2015\n",
    "    lrs_predicted = results[\"lrs_predicted\"]\n",
    "    y_test = results[\"y_test\"]\n",
    "    dropouts = results[\"quality_drops\"]\n",
    "    common_attributes = results['common_attributes']\n",
    "    \n",
    "    cllr_participants = np.mean(cllr_expert_per_year[2015])\n",
    "\n",
    "    # imagen promedio (17 comparisons)\n",
    "    lr_avg = results[\"lrs_predicted_2015\"]\n",
    "    y_avg = results[\"y_test_2015\"]    \n",
    "    \n",
    "    cllr_avg = metrics.cllr(np.asarray(lr_avg), np.asarray(y_avg)) \n",
    "\n",
    "    #get cllr per dropout\n",
    "\n",
    "    df_plot1 = pd.DataFrame()\n",
    "    for d in set(dropouts):\n",
    "        lr_d = [lr for lr,dropout in zip(lrs_predicted,dropouts) if dropout== d ]\n",
    "        y_d = [y for y,dropout in zip(y_test,dropouts) if dropout== d ]\n",
    "        cllr_d = metrics.cllr(np.asarray(lr_d), np.asarray(y_d))\n",
    "        \n",
    "\n",
    "        #solo cambio en el momento de plotear\n",
    "        df_plot1 = df_plot1.append({'dropout': 100*(1-d), 'Cllr': cllr_d},ignore_index = True)\n",
    "\n",
    "    df_plot1.sort_values(by= 'dropout', inplace = True)\n",
    "    df_plot1.dropna(inplace= True)\n",
    "\n",
    "    xa,xb = min(df_plot1.dropout),max(df_plot1.dropout)\n",
    "\n",
    "    # get cllr per common attributes\n",
    "    # filter results when dropout = 1 \n",
    "    lrs = [lr for lr,drop in zip(lrs_predicted,dropouts) if drop== 1]\n",
    "    ys = [y for y,drop in zip(y_test,dropouts) if drop== 1]\n",
    "    comatt = [ca for ca,drop in zip(common_attributes,dropouts) if drop== 1]\n",
    "\n",
    "\n",
    "    df_plot2 = pd.DataFrame()\n",
    "    for c in set(comatt):\n",
    "        lr_c = [lr for lr,com in zip(lrs,comatt) if com== c ]\n",
    "        y_c = [y for y,comm in zip(ys,comatt) if comm== c ]\n",
    "        cllr_c = metrics.cllr(np.asarray(lr_c), np.asarray(y_c))\n",
    "        df_plot2 = df_plot2.append({'Common Attributes': c, 'Cllr': cllr_c},ignore_index = True)\n",
    "        \n",
    "    df_plot2.sort_values(by= 'Common Attributes', inplace = True)\n",
    "    df_plot2.dropna(inplace= True)\n",
    "\n",
    "    # and plot with 2 different x scales\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_ylabel('Cllr')\n",
    "    ax1.set_xlabel('% of discarded pairs', color = color)\n",
    "    ax1.plot('dropout','Cllr', data = df_plot1, color = color, marker = 'o', label= 'Quality drop')\n",
    "\n",
    "    # para engañar a la leyenda 1 metemos un punto de la segunda gráfica, para luego que luego no se vea\n",
    "    \n",
    "\n",
    "\n",
    "    ax1.tick_params(axis ='x', labelcolor = color)\n",
    "   \n",
    "    \n",
    "\n",
    "    #ax1.set(xscale=\"log\")\n",
    "\n",
    "# Adding Twin Axes to plot using dataset_2\n",
    "    ax2 = ax1.twiny()\n",
    "    color = 'tab:green'\n",
    "    ax2.set_xlabel('number of common attributes', color = color)\n",
    "\n",
    "    ax2.plot('Common Attributes','Cllr', data = df_plot2, color = color, marker= '^', label = \"Matching attributes\")\n",
    "    # añadimos un plot nulo solo para que aparezca en la leyenda 1\n",
    "    ax1.plot(np.nan,np.nan, color = color, marker = '^',label = \"Matching attributes\")\n",
    "    \n",
    "    ax2.tick_params(axis ='x', labelcolor = color)\n",
    "\n",
    "        #añadimos los dos valores como rectas horizontales (ejes 1)\n",
    "    ax1.plot( [xa,xb],[cllr_avg,cllr_avg], label = 'Average quality Image', color = 'magenta')\n",
    "    ax1.plot( [xa,xb],[cllr_participants,cllr_participants], label = 'Participants', linestyle= '--', color = 'black')\n",
    "\n",
    "\n",
    "    #añadimos la leyenda 1 solo\n",
    "    #ax1.legend(loc = 'lower center')\n",
    "    ax1.legend(bbox_to_anchor=(.5, .2))\n",
    "\n",
    "    \n",
    "    plt.title(\"Cllrs per quality drop and number of common attributes\")\n",
    "    # sc_plot.set(xticks=[map(str, years)])\n",
    "\n",
    "    if save_plots:\n",
    "        savefig = os.path.join(experiment_directory, \"cllr_2015\")\n",
    "        plt.savefig(savefig, dpi=600)\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Cllr function which returns Cllr and the terms which compose it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def cllr_new(lrs, y, weights=(1, 1)):\n",
    "    \"\"\"\n",
    "    Calculates a log likelihood ratio cost (C_llr) for a series of likelihood\n",
    "    ratios.\n",
    "\n",
    "    Nico Brümmer and Johan du Preez, Application-independent evaluation of speaker detection, In: Computer Speech and\n",
    "    Language 20(2-3), 2006.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lrs : a numpy array of LRs\n",
    "    y : a numpy array of labels (0 or 1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cllr\n",
    "        the log likelihood ratio cost\n",
    "    \"\"\"\n",
    "\n",
    "    # ignore errors:\n",
    "    #   divide -> ignore divide by zero\n",
    "    #   over -> ignore scalar overflow\n",
    "    \n",
    "    #normalizamos pesos\n",
    "    #weights = weights/sum(weights)\n",
    "\n",
    "    with np.errstate(divide='ignore', over='ignore'):\n",
    "        lrs0, lrs1 = Xy_to_Xn(lrs, y) \n",
    "        cllr0_l =  np.log2(1 + lrs0) if weights[0] > 0 else np.empty()\n",
    "        cllr1_l =  np.log2(1 + 1 / lrs1) if weights[1] > 0 else np.empty()\n",
    "\n",
    "        cllr0 = weights[0] * np.mean(cllr0_l) if weights[0] > 0 else 0\n",
    "        cllr1 = weights[1] * np.mean(cllr1_l) if weights[1] > 0 else 0\n",
    "\n",
    "        #devolvemos cllr y la lista de valores que lo forman\n",
    "        return ((cllr0+cllr1)/sum(weights),np.concatenate((cllr0_l,cllr1_l)))\n",
    "\n",
    "        #cllr0 = weights[0] * np.mean(np.log2(1 + lrs0)) if weights[0] > 0 else 0\n",
    "        #cllr1 = weights[1] * np.mean(np.log2(1 + 1 / lrs1)) if weights[1] > 0 else 0\n",
    "        #return (cllr0 + cllr1) / sum(weights)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "def subplot_new(ax1,results:Dict, cllr_expert):    \n",
    "\n",
    "    # the results are only received for 2015\n",
    "    lrs_predicted = results[\"lrs_predicted\"]\n",
    "    y_test = results[\"y_test\"]\n",
    "    dropouts = results[\"quality_drops\"]\n",
    "    common_attributes = results['common_attributes']\n",
    "    \n",
    "    cllr_participants = np.mean(cllr_expert)\n",
    "\n",
    "    # imagen promedio (17 comparisons)\n",
    "    lr_avg = results[\"lrs_predicted_2015\"]\n",
    "    y_avg = results[\"y_test_2015\"]    \n",
    "    \n",
    "    cllr_avg = metrics.cllr(np.asarray(lr_avg), np.asarray(y_avg)) \n",
    "\n",
    "    #get cllr per dropout\n",
    "    with open('eggs.csv', 'w', newline='') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter= '\\t')\n",
    "    \n",
    "\n",
    "\n",
    "    df_plot1 = pd.DataFrame()\n",
    "    for d in set(dropouts):\n",
    "        lr_d = [lr for lr,dropout in zip(lrs_predicted,dropouts) if dropout== d ]\n",
    "        y_d = [y for y,dropout in zip(y_test,dropouts) if dropout== d ]\n",
    "        cllr_d = metrics.cllr(np.asarray(lr_d), np.asarray(y_d))\n",
    "\n",
    "        cllr_d1,cllr_d2 = cllr_new(np.asarray(lr_d), np.asarray(y_d))\n",
    "\n",
    "        spamwriter.writerow(f'{cllr_d1};{np.percentile(cllr_d2,[25,50,75])}')\n",
    "        \n",
    "        print(cllr_d1,np.percentile(cllr_d2,[25,50,75]))\n",
    "\n",
    "        #solo cambio en el momento de plotear\n",
    "        df_plot1 = df_plot1.append({'dropout': round(100*(1-d)), 'Cllr': cllr_d1,'Cllr2': cllr_d2},ignore_index = True)\n",
    "        \n",
    "\n",
    "\n",
    "    df_plot1.sort_values(by= 'dropout', inplace = True)\n",
    "    df_plot1.dropna(inplace= True)\n",
    "\n",
    "    #df_plot1.to_excel(\"cllr_boxplot.xlsx\")\n",
    "\n",
    "    xa,xb = min(df_plot1.dropout),max(df_plot1.dropout)\n",
    "\n",
    "    # get cllr per common attributes\n",
    "    # filter results when dropout = 1 \n",
    "    lrs = [lr for lr,drop in zip(lrs_predicted,dropouts) if drop== 1]\n",
    "    ys = [y for y,drop in zip(y_test,dropouts) if drop== 1]\n",
    "    comatt = [ca for ca,drop in zip(common_attributes,dropouts) if drop== 1]\n",
    "\n",
    "\n",
    "    df_plot2 = pd.DataFrame()\n",
    "    for c in set(comatt):\n",
    "        lr_c = [lr for lr,com in zip(lrs,comatt) if com== c ]\n",
    "        y_c = [y for y,comm in zip(ys,comatt) if comm== c ]\n",
    "        cllr_c = metrics.cllr(np.asarray(lr_c), np.asarray(y_c))\n",
    "        df_plot2 = df_plot2.append({'Common Attributes': c, 'Cllr': cllr_c},ignore_index = True)\n",
    "        \n",
    "    df_plot2.sort_values(by= 'Common Attributes', inplace = True)\n",
    "    df_plot2.dropna(inplace= True)\n",
    "\n",
    "    # and plot with 2 different x scales\n",
    "\n",
    "    #fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_ylabel('Cllr')\n",
    "    ax1.set_xlabel('% of discarded pairs', color = color)\n",
    "    \n",
    "    ax1.boxplot(df_plot1['Cllr2'],positions=df_plot1['dropout'],sym='',notch = True, manage_ticks = True, whis= 0, widths=1.2, labels=df_plot1['dropout'])\n",
    "    ax1.plot('dropout','Cllr', data = df_plot1, color = color, marker = 'o', label= 'Quality based drop')\n",
    "\n",
    "    \n",
    "    df_0drop = df_plot1.loc[(df_plot1['dropout'] == 0)]\n",
    "    ax1.scatter('dropout','Cllr', data = df_0drop, color = 'blue', marker = 's', s=[80],  label= 'Pairing all frames')\n",
    "\n",
    "\n",
    "    # para engañar a la leyenda 1 metemos un punto de la segunda gráfica, para luego que luego no se vea\n",
    "    \n",
    "\n",
    "\n",
    "    ax1.tick_params(axis ='x', labelcolor = color,size = 16)\n",
    "   \n",
    "    \n",
    "\n",
    "    #ax1.set(xscale=\"log\")\n",
    "\n",
    "# Adding Twin Axes to plot using dataset_2\n",
    "    ax2 = ax1.twiny()\n",
    "    color = 'tab:green'\n",
    "    ax2.set_xlabel('number of common attributes', color = color,fontsize = 14)\n",
    "    ax2.set_xticks(range(0,7),  fontsize = 16)\n",
    "\n",
    "    ax2.plot('Common Attributes','Cllr', data = df_plot2, color = color, marker= '^', label = \"Matching attributes\")\n",
    "    # añadimos un plot nulo solo para que aparezca en la leyenda 1\n",
    "    ax1.plot(np.nan,np.nan, color = color, marker = '^',label = \"Matching attributes\")\n",
    "\n",
    " \n",
    "    \n",
    "    #ax2.tick_params(axis ='x', labelcolor = color)\n",
    "\n",
    "        #añadimos los dos valores como rectas horizontales (ejes 1)\n",
    "    ax1.plot( [xa,xb],[cllr_avg,cllr_avg], label = 'Weighted quality image', color = 'magenta')\n",
    "    ax1.plot( [xa,xb],[cllr_participants,cllr_participants], label = 'Participants', linestyle= '--', color = 'black')\n",
    "    ax1.plot( [xa,xb],[1,1], label = 'Random system', linestyle= ':', color = 'blue')\n",
    "\n",
    "    #plots nulos para que aparezcan en la leyenda 2 y la global.\n",
    "    ax2.plot(np.nan,np.nan,  label= 'Quality based drop', color = 'red', marker = 'o')\n",
    "    ax2.scatter(np.nan,np.nan, color = 'blue', marker = 's',  label= 'Pairing all frames')\n",
    "    ax2.plot(np.nan,np.nan, label = 'Weighted quality image', color = 'magenta')\n",
    "    ax2.plot(np.nan,np.nan, label = 'Participants', linestyle= '--', color = 'black')\n",
    "    ax2.plot(np.nan,np.nan, label = 'Random system', linestyle= ':', color = 'blue')\n",
    "    \n",
    "\n",
    "    #añadimos la leyenda 1 solo\n",
    "    #ax1.legend(loc = 'lower center')\n",
    "    #ax1.legend(bbox_to_anchor=(.5, .2))\n",
    "\n",
    "    # plt.title(\"Cllrs per quality drop and number of common attributes\")\n",
    "    # sc_plot.set(xticks=[map(str, years)])\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lr-video",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
